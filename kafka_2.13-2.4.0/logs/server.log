[2020-04-02 09:51:19,809] INFO Reading configuration from: C:\kafka_2.13-2.4.0\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:51:19,871] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:51:19,871] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:51:19,887] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-02 09:51:19,887] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-02 09:51:19,887] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-02 09:51:19,887] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-02 09:51:19,902] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-02 09:51:20,027] INFO Reading configuration from: C:\kafka_2.13-2.4.0\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:51:20,027] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:51:20,027] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:51:20,027] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-02 09:51:20,074] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-02 09:51:20,214] INFO Server environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,214] INFO Server environment:host.name=DELL-PC (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,214] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,214] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,214] INFO Server environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,214] INFO Server environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:os.name=Windows 7 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:os.version=6.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:user.name=DELL (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:user.home=C:\Users\DELL (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-completed\11-pos-fanout\11-pos-fanout\scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,230] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\kafka_2.13-2.4.0\data\zookeeper\version-2 snapdir C:\kafka_2.13-2.4.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:20,386] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-02 09:51:20,620] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-02 09:51:20,636] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-02 09:51:20,815] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-02 09:51:20,838] INFO Reading snapshot C:\kafka_2.13-2.4.0\data\zookeeper\version-2\snapshot.138 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-04-02 09:51:21,088] INFO Snapshotting: 0x1cc to C:\kafka_2.13-2.4.0\data\zookeeper\version-2\snapshot.1cc (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-02 09:51:21,225] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-02 09:51:27,768] INFO Expiring session 0x100012229b40001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:27,768] INFO Expiring session 0x100012229b40000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:27,769] INFO Expiring session 0x100012229b40002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:51:27,771] INFO Creating new log file: log.1cd (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-02 09:53:46,572] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-02 09:53:51,492] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-02 09:53:58,859] INFO starting (kafka.server.KafkaServer)
[2020-04-02 09:53:58,862] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-02 09:53:58,926] INFO starting (kafka.server.KafkaServer)
[2020-04-02 09:53:58,935] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-02 09:53:59,421] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:53:59,424] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:53:59,587] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,587] INFO Client environment:host.name=DELL-PC (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,588] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,588] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,588] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,588] INFO Client environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:os.name=Windows 7 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:os.version=6.1 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:host.name=DELL-PC (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:user.name=DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,591] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:user.home=C:\Users\DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-completed\11-pos-fanout\11-pos-fanout\scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,592] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,599] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@636be97c (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,603] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-02 09:53:59,592] INFO Client environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,610] INFO Client environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,610] INFO Client environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:os.name=Windows 7 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:os.version=6.1 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:user.name=DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:user.home=C:\Users\DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-completed\11-pos-fanout\11-pos-fanout\scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,611] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,612] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,612] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,619] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@636be97c (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:53:59,777] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-02 09:53:59,780] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-02 09:53:59,866] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-02 09:53:59,976] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,000] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:00,265] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,270] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:49290, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,334] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-02 09:54:00,350] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,553] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:00,572] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,576] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:49291, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,624] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100000bd8b20000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,656] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:00,675] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x100000bd8b20001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:00,695] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:01,393] INFO starting (kafka.server.KafkaServer)
[2020-04-02 09:54:01,399] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-02 09:54:01,459] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:01,484] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,485] INFO Client environment:host.name=DELL-PC (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,485] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,485] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,485] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,485] INFO Client environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,490] INFO Client environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,490] INFO Client environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,490] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,490] INFO Client environment:os.name=Windows 7 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:os.version=6.1 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:user.name=DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:user.home=C:\Users\DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-completed\11-pos-fanout\11-pos-fanout\scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,491] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,499] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@636be97c (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:54:01,514] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-02 09:54:01,596] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-02 09:54:01,613] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:01,618] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:01,691] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:01,696] INFO Socket connection established, initiating session, client: /127.0.0.1:49294, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:01,753] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x100000bd8b20002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:54:01,767] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:54:06,229] INFO Cluster ID = uC5-M0G5Qy-3qM8_m3M3yQ (kafka.server.KafkaServer)
[2020-04-02 09:54:06,246] INFO Cluster ID = uC5-M0G5Qy-3qM8_m3M3yQ (kafka.server.KafkaServer)
[2020-04-02 09:54:06,247] INFO Cluster ID = uC5-M0G5Qy-3qM8_m3M3yQ (kafka.server.KafkaServer)
[2020-04-02 09:54:07,249] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:54:07,251] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9093
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:54:07,294] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:54:07,273] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9094
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:54:07,309] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9093
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:54:07,358] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9094
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:54:08,033] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,033] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,034] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,034] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,034] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,034] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,038] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,038] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,038] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:54:08,901] INFO Loading logs. (kafka.log.LogManager)
[2020-04-02 09:54:08,916] INFO Loading logs. (kafka.log.LogManager)
[2020-04-02 09:54:08,947] INFO Loading logs. (kafka.log.LogManager)
[2020-04-02 09:54:10,260] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:10,269] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:10,271] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:10,276] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:10,383] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:10,390] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,572] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,603] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1686 ms (kafka.log.Log)
[2020-04-02 09:54:11,607] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,617] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1931 ms (kafka.log.Log)
[2020-04-02 09:54:11,727] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:11,727] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,749] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:11,750] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,764] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,768] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2020-04-02 09:54:11,810] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,818] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2132 ms (kafka.log.Log)
[2020-04-02 09:54:11,850] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,854] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 176 ms (kafka.log.Log)
[2020-04-02 09:54:11,910] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:11,910] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,935] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:11,935] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,946] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:11,950] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 90 ms (kafka.log.Log)
[2020-04-02 09:54:12,025] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,025] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,050] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,051] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,237] INFO [ProducerStateManager partition=hello-producer-topic-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,269] INFO [ProducerStateManager partition=hello-producer-topic-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,273] INFO [ProducerStateManager partition=hello-producer-topic-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,378] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,382] INFO [ProducerStateManager partition=hello-producer-topic-0] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,396] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 535 ms (kafka.log.Log)
[2020-04-02 09:54:12,396] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,401] INFO [ProducerStateManager partition=hello-producer-topic-0] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,409] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 629 ms (kafka.log.Log)
[2020-04-02 09:54:12,474] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,475] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,496] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,500] INFO [ProducerStateManager partition=hello-producer-topic-0] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,509] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 553 ms (kafka.log.Log)
[2020-04-02 09:54:12,565] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,565] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,595] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,596] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,622] INFO [ProducerStateManager partition=hello-producer-topic-1] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,665] INFO [ProducerStateManager partition=hello-producer-topic-1] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,677] INFO [ProducerStateManager partition=hello-producer-topic-1] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,733] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,734] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,736] INFO [ProducerStateManager partition=hello-producer-topic-1] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-1\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,737] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 330 ms (kafka.log.Log)
[2020-04-02 09:54:12,738] INFO [ProducerStateManager partition=hello-producer-topic-1] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-1\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,738] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,739] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 222 ms (kafka.log.Log)
[2020-04-02 09:54:12,745] INFO [ProducerStateManager partition=hello-producer-topic-1] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-1\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,746] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 288 ms (kafka.log.Log)
[2020-04-02 09:54:12,792] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,792] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,813] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,813] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,832] INFO [ProducerStateManager partition=hello-producer-topic-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,845] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,848] INFO [ProducerStateManager partition=hello-producer-topic-2] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,850] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 102 ms (kafka.log.Log)
[2020-04-02 09:54:12,872] INFO [ProducerStateManager partition=hello-producer-topic-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,898] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,902] INFO [ProducerStateManager partition=hello-producer-topic-2] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,903] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 145 ms (kafka.log.Log)
[2020-04-02 09:54:12,942] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:12,943] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:12,980] INFO [ProducerStateManager partition=hello-producer-topic-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:12,999] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,003] INFO [ProducerStateManager partition=hello-producer-topic-2] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,003] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 258 ms (kafka.log.Log)
[2020-04-02 09:54:13,014] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,015] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,020] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,020] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,060] INFO [ProducerStateManager partition=hello-producer-topic-3] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,071] INFO [ProducerStateManager partition=hello-producer-topic-3] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,087] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,090] INFO [ProducerStateManager partition=hello-producer-topic-3] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-3\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,091] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 183 ms (kafka.log.Log)
[2020-04-02 09:54:13,125] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,133] INFO [ProducerStateManager partition=hello-producer-topic-3] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-3\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,134] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 276 ms (kafka.log.Log)
[2020-04-02 09:54:13,159] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,159] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,179] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,180] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,241] INFO [ProducerStateManager partition=hello-producer-topic-4] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,259] INFO [ProducerStateManager partition=hello-producer-topic-3] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,266] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,269] INFO [ProducerStateManager partition=hello-producer-topic-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-4\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,270] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 162 ms (kafka.log.Log)
[2020-04-02 09:54:13,317] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,317] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,392] INFO [ProducerStateManager partition=hello-producer-topic-4] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,448] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,448] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,533] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,537] INFO [ProducerStateManager partition=hello-producer-topic-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-4\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,538] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,539] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 389 ms (kafka.log.Log)
[2020-04-02 09:54:13,543] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 266 ms (kafka.log.Log)
[2020-04-02 09:54:13,576] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,576] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,591] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,593] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,597] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2020-04-02 09:54:13,610] INFO [ProducerStateManager partition=hello-producer-topic-3] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-3\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:13,612] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 580 ms (kafka.log.Log)
[2020-04-02 09:54:13,692] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,692] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,695] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,695] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,710] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,715] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 112 ms (kafka.log.Log)
[2020-04-02 09:54:13,726] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,727] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,728] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,729] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 170 ms (kafka.log.Log)
[2020-04-02 09:54:13,753] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,753] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,769] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,773] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 53 ms (kafka.log.Log)
[2020-04-02 09:54:13,803] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,804] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,822] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,822] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,845] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,850] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 113 ms (kafka.log.Log)
[2020-04-02 09:54:13,859] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:13,864] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2020-04-02 09:54:13,981] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:13,982] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,004] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,008] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 133 ms (kafka.log.Log)
[2020-04-02 09:54:14,042] INFO [ProducerStateManager partition=hello-producer-topic-4] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:14,060] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,060] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,066] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,070] INFO [ProducerStateManager partition=hello-producer-topic-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-4\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:14,071] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 449 ms (kafka.log.Log)
[2020-04-02 09:54:14,102] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,103] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,104] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,106] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 250 ms (kafka.log.Log)
[2020-04-02 09:54:14,115] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,118] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 38 ms (kafka.log.Log)
[2020-04-02 09:54:14,129] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,130] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,142] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,146] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 130 ms (kafka.log.Log)
[2020-04-02 09:54:14,149] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,149] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,169] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,173] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2020-04-02 09:54:14,207] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,207] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,218] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,225] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 114 ms (kafka.log.Log)
[2020-04-02 09:54:14,267] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,267] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,285] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,289] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 137 ms (kafka.log.Log)
[2020-04-02 09:54:14,333] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,333] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,358] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,361] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2020-04-02 09:54:14,366] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,367] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,385] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,390] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 146 ms (kafka.log.Log)
[2020-04-02 09:54:14,426] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,427] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,455] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,456] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,501] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,506] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 209 ms (kafka.log.Log)
[2020-04-02 09:54:14,518] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,520] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,521] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,522] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 152 ms (kafka.log.Log)
[2020-04-02 09:54:14,539] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,543] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 147 ms (kafka.log.Log)
[2020-04-02 09:54:14,584] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,584] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,605] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,606] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,626] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,630] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 103 ms (kafka.log.Log)
[2020-04-02 09:54:14,671] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,672] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,676] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,680] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 164 ms (kafka.log.Log)
[2020-04-02 09:54:14,739] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:14,743] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 196 ms (kafka.log.Log)
[2020-04-02 09:54:14,989] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:14,989] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,029] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,029] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,087] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,093] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 409 ms (kafka.log.Log)
[2020-04-02 09:54:15,103] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,103] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,137] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,140] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 392 ms (kafka.log.Log)
[2020-04-02 09:54:15,186] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,186] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,212] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,216] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2020-04-02 09:54:15,306] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,310] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 669 ms (kafka.log.Log)
[2020-04-02 09:54:15,333] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,334] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,409] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,410] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,426] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,426] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,526] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,529] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 214 ms (kafka.log.Log)
[2020-04-02 09:54:15,546] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,550] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 449 ms (kafka.log.Log)
[2020-04-02 09:54:15,580] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,583] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 363 ms (kafka.log.Log)
[2020-04-02 09:54:15,599] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,599] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,613] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,617] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2020-04-02 09:54:15,625] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,625] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,638] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,639] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,658] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,661] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 124 ms (kafka.log.Log)
[2020-04-02 09:54:15,669] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,673] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 85 ms (kafka.log.Log)
[2020-04-02 09:54:15,685] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,685] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,717] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,717] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,772] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,782] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,784] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 163 ms (kafka.log.Log)
[2020-04-02 09:54:15,786] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 111 ms (kafka.log.Log)
[2020-04-02 09:54:15,804] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,804] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,842] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,842] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,858] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,862] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2020-04-02 09:54:15,935] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,935] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,955] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:15,958] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,964] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 174 ms (kafka.log.Log)
[2020-04-02 09:54:15,969] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:15,972] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\__consumer_offsets-23\00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:15,979] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 299 ms (kafka.log.Log)
[2020-04-02 09:54:15,993] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:15,993] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,014] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,017] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 151 ms (kafka.log.Log)
[2020-04-02 09:54:16,046] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,046] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,054] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:16,080] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,084] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\__consumer_offsets-26\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:16,084] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 101 ms (kafka.log.Log)
[2020-04-02 09:54:16,104] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,104] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,120] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,124] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 155 ms (kafka.log.Log)
[2020-04-02 09:54:16,248] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,248] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,281] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,286] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 265 ms (kafka.log.Log)
[2020-04-02 09:54:16,322] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,323] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,352] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,356] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 228 ms (kafka.log.Log)
[2020-04-02 09:54:16,380] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,380] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,466] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,467] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,522] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,522] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,526] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 229 ms (kafka.log.Log)
[2020-04-02 09:54:16,526] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 435 ms (kafka.log.Log)
[2020-04-02 09:54:16,563] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,563] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,575] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:16,585] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,585] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,625] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,628] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\__consumer_offsets-24\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:16,629] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 267 ms (kafka.log.Log)
[2020-04-02 09:54:16,649] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,653] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 122 ms (kafka.log.Log)
[2020-04-02 09:54:16,760] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,760] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,827] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,828] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,838] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-04-02 09:54:16,843] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,844] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,874] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,874] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,878] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\__consumer_offsets-4\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:54:16,878] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 345 ms (kafka.log.Log)
[2020-04-02 09:54:16,880] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 221 ms (kafka.log.Log)
[2020-04-02 09:54:16,929] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,929] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,943] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:16,947] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2020-04-02 09:54:16,992] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:16,993] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,001] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,001] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,007] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,011] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 127 ms (kafka.log.Log)
[2020-04-02 09:54:17,017] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,020] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,021] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2020-04-02 09:54:17,024] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 391 ms (kafka.log.Log)
[2020-04-02 09:54:17,128] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,129] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,136] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,137] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,148] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,151] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,152] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,152] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 123 ms (kafka.log.Log)
[2020-04-02 09:54:17,153] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,159] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 144 ms (kafka.log.Log)
[2020-04-02 09:54:17,281] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,285] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 260 ms (kafka.log.Log)
[2020-04-02 09:54:17,296] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,296] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,300] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,300] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,369] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,369] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,373] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 208 ms (kafka.log.Log)
[2020-04-02 09:54:17,373] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 217 ms (kafka.log.Log)
[2020-04-02 09:54:17,474] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,474] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,487] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,488] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,493] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,498] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 203 ms (kafka.log.Log)
[2020-04-02 09:54:17,509] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,513] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 136 ms (kafka.log.Log)
[2020-04-02 09:54:17,563] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,564] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,566] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,567] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,593] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,594] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,621] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,622] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,623] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,624] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 108 ms (kafka.log.Log)
[2020-04-02 09:54:17,626] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 109 ms (kafka.log.Log)
[2020-04-02 09:54:17,629] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 247 ms (kafka.log.Log)
[2020-04-02 09:54:17,679] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,680] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,693] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,697] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2020-04-02 09:54:17,754] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,755] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,759] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,760] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,768] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,772] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2020-04-02 09:54:17,787] INFO Logs loading complete in 8840 ms. (kafka.log.LogManager)
[2020-04-02 09:54:17,788] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,789] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,790] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,794] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 160 ms (kafka.log.Log)
[2020-04-02 09:54:17,805] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,809] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 177 ms (kafka.log.Log)
[2020-04-02 09:54:17,869] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:17,869] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,875] INFO Logs loading complete in 8958 ms. (kafka.log.LogManager)
[2020-04-02 09:54:17,907] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:17,911] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 93 ms (kafka.log.Log)
[2020-04-02 09:54:17,973] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-02 09:54:17,979] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-02 09:54:17,986] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-02 09:54:17,999] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-02 09:54:18,015] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:18,016] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:18,041] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:18,048] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 133 ms (kafka.log.Log)
[2020-04-02 09:54:18,184] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:18,184] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:18,211] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:18,215] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 160 ms (kafka.log.Log)
[2020-04-02 09:54:18,516] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:18,517] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:18,642] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:18,646] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 428 ms (kafka.log.Log)
[2020-04-02 09:54:19,499] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:54:19,499] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:19,519] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:54:19,523] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 757 ms (kafka.log.Log)
[2020-04-02 09:54:19,782] INFO Logs loading complete in 10881 ms. (kafka.log.LogManager)
[2020-04-02 09:54:19,846] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-02 09:54:19,849] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-02 09:54:23,939] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-02 09:54:24,038] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-02 09:54:24,187] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-02 09:54:24,416] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-02 09:54:24,421] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-02 09:54:24,453] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-02 09:54:24,459] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-02 09:54:24,562] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-02 09:54:24,566] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-02 09:54:24,764] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,775] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,774] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,779] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,774] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,779] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,776] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,777] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,781] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,780] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,781] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,782] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:24,970] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-02 09:54:25,000] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-02 09:54:25,033] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-02 09:54:25,640] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,649] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,689] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,820] INFO Stat of the created znode at /brokers/ids/1 is: 511,511,1585801465784,1585801465784,1,0,0,72057644918112256,184,0,511
 (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,822] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArraySeq(EndPoint(DELL-PC,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 511 (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,862] INFO Stat of the created znode at /brokers/ids/0 is: 510,510,1585801465784,1585801465784,1,0,0,72057644918112257,184,0,510
 (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,862] INFO Stat of the created znode at /brokers/ids/2 is: 512,512,1585801465792,1585801465792,1,0,0,72057644918112258,184,0,512
 (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,863] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArraySeq(EndPoint(DELL-PC,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 512 (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:25,863] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DELL-PC,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 510 (kafka.zk.KafkaZkClient)
[2020-04-02 09:54:27,014] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,018] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,036] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,036] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,045] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,248] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:27,250] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:27,300] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,300] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,321] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,322] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:27,525] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 204 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:27,629] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:27,645] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-02 09:54:27,646] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:27,650] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:27,644] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:27,721] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:27,721] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 43 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:27,756] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:7000,blockEndProducerId:7999) by writing to Zk with path version 8 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-02 09:54:27,916] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:8000,blockEndProducerId:8999) by writing to Zk with path version 9 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-02 09:54:28,066] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:54:28,068] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:54:28,072] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:54:28,076] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-02 09:54:28,077] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:54:28,082] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-02 09:54:28,088] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:54:28,101] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-02 09:54:28,102] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:54:28,597] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:28,638] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:28,715] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:54:28,754] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-02 09:54:28,789] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-02 09:54:29,012] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-02 09:54:29,233] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-02 09:54:29,242] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-02 09:54:29,341] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,341] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,341] INFO Kafka startTimeMs: 1585801469244 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,345] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-02 09:54:29,429] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-02 09:54:29,452] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,452] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,453] INFO Kafka startTimeMs: 1585801469234 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,456] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-02 09:54:29,497] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,497] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,497] INFO Kafka startTimeMs: 1585801469431 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:54:29,501] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-02 09:54:32,440] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, pos-1, __consumer_offsets-33, hello-producer-topic-0, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, hello-producer-topic-3, hello-producer-topic-4, __consumer_offsets-21, hadoop-sink-0, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12, shipment-0, loyalty-1, __consumer_offsets-45) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:32,579] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-29, __consumer_offsets-32, hello-producer-topic-1, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, hello-producer-topic-2, __consumer_offsets-11, loyalty-0, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, pos-0, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:32,819] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:32,821] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:32,826] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:32,828] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:32,988] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:32,988] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:32,988] INFO [Partition shipment-0 broker=1] Log loaded for partition shipment-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:32,988] INFO [Partition shipment-0 broker=1] shipment-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,004] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,004] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,016] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,016] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,022] INFO [Partition loyalty-0 broker=0] Log loaded for partition loyalty-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,022] INFO [Partition loyalty-0 broker=0] loyalty-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,211] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,211] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,213] INFO [Partition pos-1 broker=1] Log loaded for partition pos-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,213] INFO [Partition pos-1 broker=1] pos-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,226] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,226] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,238] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,238] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,270] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,270] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,272] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,273] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,370] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,370] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,412] INFO [Partition loyalty-1 broker=1] Log loaded for partition loyalty-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,412] INFO [Partition loyalty-1 broker=1] loyalty-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,415] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-34, __consumer_offsets-7, hadoop-sink-1, __consumer_offsets-46, pos-2, __consumer_offsets-25, __consumer_offsets-16, __consumer_offsets-28, shipment-1, __consumer_offsets-1, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:33,485] INFO [Partition hello-producer-topic-2 broker=0] Log loaded for partition hello-producer-topic-2 with initial high watermark 5 (kafka.cluster.Partition)
[2020-04-02 09:54:33,485] INFO [Partition hello-producer-topic-2 broker=0] hello-producer-topic-2 starts at Leader Epoch 5 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,489] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,489] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,555] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,561] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,556] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,563] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,568] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,568] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,584] INFO [Partition pos-0 broker=0] Log loaded for partition pos-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,585] INFO [Partition pos-0 broker=0] pos-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,709] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 23 (kafka.cluster.Partition)
[2020-04-02 09:54:33,709] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 2 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,718] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,718] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,728] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,728] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,741] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,742] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,925] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,925] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,927] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,928] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,970] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,971] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,995] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,996] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:33,998] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:33,998] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,019] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,019] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,063] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,063] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,065] INFO [Partition hello-producer-topic-3 broker=1] Log loaded for partition hello-producer-topic-3 with initial high watermark 36 (kafka.cluster.Partition)
[2020-04-02 09:54:34,065] INFO [Partition hello-producer-topic-3 broker=1] hello-producer-topic-3 starts at Leader Epoch 5 from offset 36. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,071] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,071] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,267] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,267] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,280] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,280] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,409] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,409] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,412] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,412] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,427] INFO [Partition hadoop-sink-0 broker=1] Log loaded for partition hadoop-sink-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,428] INFO [Partition hadoop-sink-0 broker=1] hadoop-sink-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,486] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,486] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,494] INFO [Partition hello-producer-topic-1 broker=0] Log loaded for partition hello-producer-topic-1 with initial high watermark 24 (kafka.cluster.Partition)
[2020-04-02 09:54:34,500] INFO [Partition hello-producer-topic-1 broker=0] hello-producer-topic-1 starts at Leader Epoch 4 from offset 24. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,516] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,516] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,556] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,557] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,559] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,560] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,561] INFO [Partition shipment-0 broker=0] Log loaded for partition shipment-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,573] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,574] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,577] INFO [Partition hello-producer-topic-3 broker=0] Log loaded for partition hello-producer-topic-3 with initial high watermark 36 (kafka.cluster.Partition)
[2020-04-02 09:54:34,583] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,583] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,751] INFO [Partition hello-producer-topic-4 broker=0] Log loaded for partition hello-producer-topic-4 with initial high watermark 20 (kafka.cluster.Partition)
[2020-04-02 09:54:34,781] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,781] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,781] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,781] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,781] INFO [Partition shipment-1 broker=0] Log loaded for partition shipment-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,830] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,831] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,836] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,836] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,841] INFO [Partition pos-2 broker=0] Log loaded for partition pos-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,856] INFO [Partition shipment-1 broker=2] Log loaded for partition shipment-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,856] INFO [Partition shipment-1 broker=2] shipment-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,857] INFO [Partition pos-1 broker=0] Log loaded for partition pos-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,861] INFO [Partition hello-producer-topic-0 broker=1] Log loaded for partition hello-producer-topic-0 with initial high watermark 11 (kafka.cluster.Partition)
[2020-04-02 09:54:34,861] INFO [Partition hello-producer-topic-0 broker=1] hello-producer-topic-0 starts at Leader Epoch 5 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,884] INFO [Partition hadoop-sink-0 broker=0] Log loaded for partition hadoop-sink-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,892] INFO [Partition pos-2 broker=2] Log loaded for partition pos-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,892] INFO [Partition pos-2 broker=2] pos-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,905] INFO [Partition hadoop-sink-1 broker=0] Log loaded for partition hadoop-sink-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,918] INFO [Partition loyalty-1 broker=0] Log loaded for partition loyalty-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,924] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,924] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,928] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,929] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:34,934] INFO [Partition hello-producer-topic-0 broker=0] Log loaded for partition hello-producer-topic-0 with initial high watermark 11 (kafka.cluster.Partition)
[2020-04-02 09:54:34,935] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(hadoop-sink-0, hello-producer-topic-0, shipment-0, pos-2, shipment-1, pos-1, hadoop-sink-1, loyalty-1, hello-producer-topic-4, hello-producer-topic-3) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:34,962] INFO [Partition hadoop-sink-1 broker=2] Log loaded for partition hadoop-sink-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:34,962] INFO [Partition hadoop-sink-1 broker=2] hadoop-sink-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,036] INFO [Partition hello-producer-topic-4 broker=1] Log loaded for partition hello-producer-topic-4 with initial high watermark 20 (kafka.cluster.Partition)
[2020-04-02 09:54:35,036] INFO [Partition hello-producer-topic-4 broker=1] hello-producer-topic-4 starts at Leader Epoch 4 from offset 20. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,041] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,041] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,125] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,125] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,141] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=1, host=DELL-PC:9093) for partitions HashMap(hadoop-sink-0 -> (offset=0, leaderEpoch=0), pos-1 -> (offset=0, leaderEpoch=0), hello-producer-topic-0 -> (offset=11, leaderEpoch=5), shipment-0 -> (offset=0, leaderEpoch=0), loyalty-1 -> (offset=0, leaderEpoch=0), hello-producer-topic-3 -> (offset=36, leaderEpoch=5), hello-producer-topic-4 -> (offset=20, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:35,157] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker BrokerEndPoint(id=2, host=DELL-PC:9094) for partitions HashMap(hadoop-sink-1 -> (offset=0, leaderEpoch=0), pos-2 -> (offset=0, leaderEpoch=0), shipment-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:35,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,266] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,271] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,300] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition pos-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,307] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,308] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,309] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,331] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,332] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,333] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,333] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition shipment-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,333] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,333] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,333] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition hadoop-sink-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,333] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,338] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,401] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,401] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,432] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2020-04-02 09:54:35,433] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 20 has no effect as the largest offset in the log is 19 (kafka.log.Log)
[2020-04-02 09:54:35,433] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 36 has no effect as the largest offset in the log is 35 (kafka.log.Log)
[2020-04-02 09:54:35,435] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition hadoop-sink-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,435] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,435] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition shipment-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,435] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,435] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition pos-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,436] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,436] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition loyalty-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:35,436] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:35,603] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,604] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,624] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,624] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,743] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,743] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,744] INFO [Partition hello-producer-topic-2 broker=1] Log loaded for partition hello-producer-topic-2 with initial high watermark 5 (kafka.cluster.Partition)
[2020-04-02 09:54:35,779] INFO [Partition pos-0 broker=1] Log loaded for partition pos-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,776] INFO [GroupCoordinator 0]: Loading group metadata for HelloStreams with generation 7 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:35,782] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 444 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,783] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,783] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,783] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,793] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-96857 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:35,805] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,805] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:54:35,817] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 28 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,819] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,819] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,820] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:35,887] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hadoop-sink-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,887] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition pos-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,887] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hello-producer-topic-0 at offset 11 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,887] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hello-producer-topic-3 at offset 36 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,888] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hello-producer-topic-4 at offset 20 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,888] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition shipment-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,888] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition loyalty-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,903] INFO [Partition shipment-1 broker=1] Log loaded for partition shipment-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,906] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition hadoop-sink-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,906] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition pos-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,906] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition shipment-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:35,949] INFO [Partition shipment-0 broker=2] Log loaded for partition shipment-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:35,996] INFO [Partition hello-producer-topic-2 broker=2] Log loaded for partition hello-producer-topic-2 with initial high watermark 5 (kafka.cluster.Partition)
[2020-04-02 09:54:36,026] INFO [Partition pos-2 broker=1] Log loaded for partition pos-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,177] INFO [Partition hello-producer-topic-3 broker=2] Log loaded for partition hello-producer-topic-3 with initial high watermark 36 (kafka.cluster.Partition)
[2020-04-02 09:54:36,206] INFO [Partition loyalty-0 broker=1] Log loaded for partition loyalty-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,262] INFO [Partition hadoop-sink-1 broker=1] Log loaded for partition hadoop-sink-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,270] INFO [Partition pos-0 broker=2] Log loaded for partition pos-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,351] INFO [Partition hello-producer-topic-4 broker=2] Log loaded for partition hello-producer-topic-4 with initial high watermark 20 (kafka.cluster.Partition)
[2020-04-02 09:54:36,430] INFO [Partition hello-producer-topic-1 broker=1] Log loaded for partition hello-producer-topic-1 with initial high watermark 24 (kafka.cluster.Partition)
[2020-04-02 09:54:36,432] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(pos-2, shipment-1, pos-0, loyalty-0, hadoop-sink-1, hello-producer-topic-2, hello-producer-topic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:36,545] INFO [Partition loyalty-0 broker=2] Log loaded for partition loyalty-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,568] INFO [Partition pos-1 broker=2] Log loaded for partition pos-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,606] INFO [Partition hadoop-sink-0 broker=2] Log loaded for partition hadoop-sink-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,565] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:36,571] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=2, host=DELL-PC:9094) for partitions HashMap(hadoop-sink-1 -> (offset=0, leaderEpoch=0), pos-2 -> (offset=0, leaderEpoch=0), shipment-1 -> (offset=0, leaderEpoch=0)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:36,818] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition pos-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:36,855] INFO [Partition loyalty-1 broker=2] Log loaded for partition loyalty-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:54:36,838] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:36,924] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition shipment-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:36,924] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:36,924] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition hadoop-sink-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:36,924] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:36,927] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=DELL-PC:9092) for partitions HashMap(hello-producer-topic-2 -> (offset=5, leaderEpoch=5), loyalty-0 -> (offset=0, leaderEpoch=0), pos-0 -> (offset=0, leaderEpoch=0), hello-producer-topic-1 -> (offset=24, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:36,946] INFO [Partition hello-producer-topic-0 broker=2] Log loaded for partition hello-producer-topic-0 with initial high watermark 11 (kafka.cluster.Partition)
[2020-04-02 09:54:36,948] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:36,988] INFO [Partition hello-producer-topic-1 broker=2] Log loaded for partition hello-producer-topic-1 with initial high watermark 24 (kafka.cluster.Partition)
[2020-04-02 09:54:36,990] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(hadoop-sink-0, hello-producer-topic-0, shipment-0, pos-0, pos-1, loyalty-0, loyalty-1, hello-producer-topic-4, hello-producer-topic-3, hello-producer-topic-2, hello-producer-topic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:37,047] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition pos-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,047] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition shipment-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,047] ERROR [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error for partition hadoop-sink-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,084] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=DELL-PC:9093) for partitions HashMap(hadoop-sink-0 -> (offset=0, leaderEpoch=0), pos-1 -> (offset=0, leaderEpoch=0), hello-producer-topic-0 -> (offset=11, leaderEpoch=5), shipment-0 -> (offset=0, leaderEpoch=0), loyalty-1 -> (offset=0, leaderEpoch=0), hello-producer-topic-3 -> (offset=36, leaderEpoch=5), hello-producer-topic-4 -> (offset=20, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:37,089] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,102] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2020-04-02 09:54:37,102] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 24 has no effect as the largest offset in the log is 23 (kafka.log.Log)
[2020-04-02 09:54:37,103] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition pos-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,103] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,103] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition loyalty-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,135] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hadoop-sink-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,135] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hello-producer-topic-0 at offset 11 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,135] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition shipment-0 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,135] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition pos-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,135] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition loyalty-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,136] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hello-producer-topic-4 at offset 20 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,136] ERROR [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error for partition hello-producer-topic-3 at offset 36 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,140] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,150] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,257] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,257] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,258] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,259] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,122] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=DELL-PC:9092) for partitions HashMap(hello-producer-topic-2 -> (offset=5, leaderEpoch=5), loyalty-0 -> (offset=0, leaderEpoch=0), pos-0 -> (offset=0, leaderEpoch=0), hello-producer-topic-1 -> (offset=24, leaderEpoch=4)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:54:37,320] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition hadoop-sink-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,330] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition pos-2 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,331] ERROR [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error for partition shipment-1 at offset 0 (kafka.server.ReplicaFetcherThread)
org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
[2020-04-02 09:54:37,501] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 183 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,503] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,363] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,507] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,508] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,508] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,509] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,509] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,509] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,523] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 14 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,524] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,537] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2020-04-02 09:54:37,541] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 24 has no effect as the largest offset in the log is 23 (kafka.log.Log)
[2020-04-02 09:54:37,522] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2020-04-02 09:54:37,390] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,572] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,573] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,590] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,592] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,592] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,593] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,593] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,593] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,593] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,594] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,594] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,594] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,602] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,635] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,635] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,635] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,635] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,635] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,635] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,624] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition pos-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,656] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,656] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition loyalty-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,656] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,744] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-31216 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:37,776] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 131 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,776] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,777] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,777] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,777] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,777] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,778] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:37,602] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 20 has no effect as the largest offset in the log is 19 (kafka.log.Log)
[2020-04-02 09:54:37,786] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 36 has no effect as the largest offset in the log is 35 (kafka.log.Log)
[2020-04-02 09:54:37,787] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition hadoop-sink-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,787] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,787] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition shipment-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,787] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,787] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition pos-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,787] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,787] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition loyalty-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:54:37,787] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:54:37,986] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-17735 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:38,016] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 492 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:38,102] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 86 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:38,102] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:38,104] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:38,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:38,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:38,105] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:54:45,946] INFO [GroupCoordinator 0]: Member consumer-console-consumer-96857-1-ee175b57-a602-4adf-853f-e3449d238c71 in group console-consumer-96857 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:45,961] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-96857 in state PreparingRebalance with old generation 1 (__consumer_offsets-26) (reason: removing member consumer-console-consumer-96857-1-ee175b57-a602-4adf-853f-e3449d238c71 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:45,961] INFO [GroupCoordinator 0]: Group console-consumer-96857 with generation 2 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:47,818] INFO [GroupCoordinator 2]: Member consumer-console-consumer-31216-1-bf21819c-6406-4625-abac-a43c1f67f682 in group console-consumer-31216 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:47,818] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-31216 in state PreparingRebalance with old generation 1 (__consumer_offsets-4) (reason: removing member consumer-console-consumer-31216-1-bf21819c-6406-4625-abac-a43c1f67f682 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:47,833] INFO [GroupCoordinator 2]: Group console-consumer-31216 with generation 2 is now empty (__consumer_offsets-4) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:48,052] INFO [GroupCoordinator 1]: Member consumer-console-consumer-17735-1-036f2f08-bc0a-4c02-85e6-84fa7882fecb in group console-consumer-17735 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:48,099] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-17735 in state PreparingRebalance with old generation 1 (__consumer_offsets-24) (reason: removing member consumer-console-consumer-17735-1-036f2f08-bc0a-4c02-85e6-84fa7882fecb on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:48,114] INFO [GroupCoordinator 1]: Group console-consumer-17735 with generation 2 is now empty (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:51,465] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-46600 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member consumer-console-consumer-46600-1-bd2b8a0d-6ac4-4550-945f-d3ae5f929cd8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:51,479] INFO [GroupCoordinator 2]: Stabilized group console-consumer-46600 generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:51,511] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-46600 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:55,665] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-13490 in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member consumer-console-consumer-13490-1-79c43bfa-cc47-47db-b766-9572b3c99de8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:55,726] INFO [GroupCoordinator 0]: Stabilized group console-consumer-13490 generation 1 (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:54:55,758] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-13490 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:55:05,499] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-38413 in state PreparingRebalance with old generation 0 (__consumer_offsets-10) (reason: Adding new member consumer-console-consumer-38413-1-5bedf988-9285-4983-a684-f4380f6fde39 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:55:05,506] INFO [GroupCoordinator 2]: Stabilized group console-consumer-38413 generation 1 (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:55:05,521] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-38413 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:55:32,250] WARN Session 0x100000bd8b20000 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2020-04-02 09:55:32,250] WARN Session 0x100000bd8b20001 for server localhost/0:0:0:0:0:0:0:1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2020-04-02 09:55:32,250] WARN Session 0x100000bd8b20002 for server localhost/127.0.0.1:2181, unexpected error, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at sun.nio.ch.SocketDispatcher.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:75)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:363)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1223)
[2020-04-02 09:55:32,297] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1825891575, epoch=105) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:107)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:196)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:39)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:286)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:133)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:132)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:114)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-04-02 09:55:32,297] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1825891575, epoch=105), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:107)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:196)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:39)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:286)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:133)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:132)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:114)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-04-02 09:55:32,312] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=810009918, epoch=102) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:107)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:196)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:39)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:286)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:133)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:132)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:114)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-04-02 09:55:32,312] WARN [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=810009918, epoch=102), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:107)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:196)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:39)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:286)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:133)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:132)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:114)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-04-02 09:56:43,750] INFO Reading configuration from: C:\kafka_2.13-2.4.0\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:56:43,766] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:56:43,766] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:56:43,766] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-02 09:56:43,766] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-02 09:56:43,766] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-04-02 09:56:43,766] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-04-02 09:56:43,766] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-04-02 09:56:43,813] INFO Reading configuration from: C:\kafka_2.13-2.4.0\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:56:43,813] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:56:43,813] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-04-02 09:56:43,813] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-04-02 09:56:43,813] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-02 09:56:43,859] INFO Server environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,859] INFO Server environment:host.name=DELL-PC (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,859] INFO Server environment:java.version=1.8.0_221 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,859] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,859] INFO Server environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,859] INFO Server environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:os.name=Windows 7 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:os.version=6.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:user.name=DELL (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:user.home=C:\Users\DELL (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-starter\11-pos-fanout\scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,875] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:43,891] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir C:\kafka_2.13-2.4.0\data\zookeeper\version-2 snapdir C:\kafka_2.13-2.4.0\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:44,000] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-04-02 09:56:44,000] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 1 selector thread(s), 8 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-02 09:56:44,015] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-04-02 09:56:44,080] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-04-02 09:56:44,087] INFO Reading snapshot C:\kafka_2.13-2.4.0\data\zookeeper\version-2\snapshot.1cc (org.apache.zookeeper.server.persistence.FileSnap)
[2020-04-02 09:56:44,178] INFO Snapshotting: 0x20c to C:\kafka_2.13-2.4.0\data\zookeeper\version-2\snapshot.20c (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-04-02 09:56:44,267] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-04-02 09:56:51,775] INFO Expiring session 0x100000bd8b20001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:51,775] INFO Expiring session 0x100000bd8b20000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:51,776] INFO Expiring session 0x100000bd8b20002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2020-04-02 09:56:51,779] INFO Creating new log file: log.20d (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-04-02 09:57:04,502] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-02 09:57:06,193] INFO starting (kafka.server.KafkaServer)
[2020-04-02 09:57:06,196] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-02 09:57:06,268] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:06,320] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,321] INFO Client environment:host.name=DELL-PC (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,321] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,321] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,322] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,322] INFO Client environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,324] INFO Client environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:os.name=Windows 7 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:os.version=6.1 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:user.name=DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:user.home=C:\Users\DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,325] INFO Client environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-starter\11-pos-fanout\scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,326] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,327] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,327] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,335] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@636be97c (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:06,350] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-02 09:57:06,450] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-02 09:57:06,480] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:06,485] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:06,591] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:06,607] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:49458, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:06,648] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000010c6a70000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:06,661] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:08,007] INFO Cluster ID = uC5-M0G5Qy-3qM8_m3M3yQ (kafka.server.KafkaServer)
[2020-04-02 09:57:08,316] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:57:08,393] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:57:08,525] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:08,527] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:08,527] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:08,680] INFO Loading logs. (kafka.log.LogManager)
[2020-04-02 09:57:08,855] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:08,861] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,016] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,026] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 257 ms (kafka.log.Log)
[2020-04-02 09:57:09,061] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,061] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,076] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,080] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-04-02 09:57:09,092] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,092] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,140] INFO [ProducerStateManager partition=hello-producer-topic-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,197] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,202] INFO [ProducerStateManager partition=hello-producer-topic-0] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,213] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 128 ms (kafka.log.Log)
[2020-04-02 09:57:09,230] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,230] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,245] INFO [ProducerStateManager partition=hello-producer-topic-1] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,275] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,278] INFO [ProducerStateManager partition=hello-producer-topic-1] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-1\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,279] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 60 ms (kafka.log.Log)
[2020-04-02 09:57:09,293] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,294] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,305] INFO [ProducerStateManager partition=hello-producer-topic-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,346] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,349] INFO [ProducerStateManager partition=hello-producer-topic-2] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,350] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 64 ms (kafka.log.Log)
[2020-04-02 09:57:09,362] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,363] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,383] INFO [ProducerStateManager partition=hello-producer-topic-3] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,394] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,397] INFO [ProducerStateManager partition=hello-producer-topic-3] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-3\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,398] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 42 ms (kafka.log.Log)
[2020-04-02 09:57:09,408] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,408] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,418] INFO [ProducerStateManager partition=hello-producer-topic-4] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,428] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,431] INFO [ProducerStateManager partition=hello-producer-topic-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\hello-producer-topic-4\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,432] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:09,442] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,442] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,475] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,479] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 43 ms (kafka.log.Log)
[2020-04-02 09:57:09,490] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,490] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,500] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,503] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-04-02 09:57:09,514] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,515] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,531] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,535] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-04-02 09:57:09,546] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,546] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,556] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,559] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2020-04-02 09:57:09,572] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,572] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,583] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,586] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-04-02 09:57:09,601] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,602] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,612] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,616] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2020-04-02 09:57:09,628] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,629] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,643] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,647] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-04-02 09:57:09,682] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,682] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,701] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,704] INFO [Log partition=__consumer_offsets-11, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2020-04-02 09:57:09,717] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,718] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,791] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,794] INFO [Log partition=__consumer_offsets-14, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2020-04-02 09:57:09,805] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,805] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,822] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,826] INFO [Log partition=__consumer_offsets-17, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-04-02 09:57:09,838] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,839] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,864] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,867] INFO [Log partition=__consumer_offsets-2, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2020-04-02 09:57:09,887] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,888] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,903] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,916] INFO [Log partition=__consumer_offsets-20, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 44 ms (kafka.log.Log)
[2020-04-02 09:57:09,926] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,926] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,950] INFO [ProducerStateManager partition=__consumer_offsets-23] Writing producer snapshot at offset 23 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,970] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 23 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,974] INFO [ProducerStateManager partition=__consumer_offsets-23] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\__consumer_offsets-23\00000000000000000023.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:09,975] INFO [Log partition=__consumer_offsets-23, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 23 in 55 ms (kafka.log.Log)
[2020-04-02 09:57:09,986] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:09,986] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:09,996] INFO [ProducerStateManager partition=__consumer_offsets-26] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:10,059] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,062] INFO [ProducerStateManager partition=__consumer_offsets-26] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\__consumer_offsets-26\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:10,063] INFO [Log partition=__consumer_offsets-26, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 84 ms (kafka.log.Log)
[2020-04-02 09:57:10,073] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,074] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,090] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,093] INFO [Log partition=__consumer_offsets-29, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-04-02 09:57:10,104] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,104] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,131] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,134] INFO [Log partition=__consumer_offsets-32, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-04-02 09:57:10,147] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,147] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,165] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,169] INFO [Log partition=__consumer_offsets-35, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:10,178] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,179] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,196] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,199] INFO [Log partition=__consumer_offsets-38, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-04-02 09:57:10,220] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,220] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,238] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,242] INFO [Log partition=__consumer_offsets-41, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:10,255] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,255] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,283] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,286] INFO [Log partition=__consumer_offsets-44, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2020-04-02 09:57:10,297] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,297] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,311] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,314] INFO [Log partition=__consumer_offsets-47, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-02 09:57:10,322] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,322] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,343] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,347] INFO [Log partition=__consumer_offsets-5, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:10,355] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:10,356] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,364] INFO [ProducerStateManager partition=__consumer_offsets-8] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:10,386] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:10,389] INFO [ProducerStateManager partition=__consumer_offsets-8] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-0\__consumer_offsets-8\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:10,390] INFO [Log partition=__consumer_offsets-8, dir=C:\kafka_2.13-2.4.0\data\kafka-0] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 40 ms (kafka.log.Log)
[2020-04-02 09:57:10,405] INFO Logs loading complete in 1724 ms. (kafka.log.LogManager)
[2020-04-02 09:57:10,441] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-02 09:57:10,444] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-02 09:57:11,591] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-04-02 09:57:11,720] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-02 09:57:11,724] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-02 09:57:11,899] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:12,001] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:12,049] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:12,063] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:12,064] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-02 09:57:12,385] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:12,570] INFO Stat of the created znode at /brokers/ids/0 is: 542,542,1585801632548,1585801632548,1,0,0,72057666090237952,184,0,542
 (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:12,572] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArraySeq(EndPoint(DELL-PC,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 542 (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:12,941] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:12,941] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:13,082] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:13,118] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:13,124] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:13,149] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 19 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:13,213] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:9000,blockEndProducerId:9999) by writing to Zk with path version 10 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-02 09:57:13,296] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:57:13,303] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:57:13,348] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-02 09:57:13,718] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:13,745] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-02 09:57:14,168] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-02 09:57:14,711] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-02 09:57:14,738] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:14,738] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:14,738] INFO Kafka startTimeMs: 1585801634717 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:14,743] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-04-02 09:57:15,564] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-29, __consumer_offsets-32, hello-producer-topic-1, __consumer_offsets-41, __consumer_offsets-23, __consumer_offsets-47, hello-producer-topic-2, __consumer_offsets-11, loyalty-0, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, pos-0, __consumer_offsets-44, __consumer_offsets-5, __consumer_offsets-26) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:15,662] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,663] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:15,801] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,801] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:15,848] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,848] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:15,870] INFO [Partition loyalty-0 broker=0] Log loaded for partition loyalty-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,870] INFO [Partition loyalty-0 broker=0] loyalty-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:15,912] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,912] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:15,944] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,944] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:15,978] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:15,978] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,000] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,001] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,082] INFO [Partition hello-producer-topic-2 broker=0] Log loaded for partition hello-producer-topic-2 with initial high watermark 5 (kafka.cluster.Partition)
[2020-04-02 09:57:16,082] INFO [Partition hello-producer-topic-2 broker=0] hello-producer-topic-2 starts at Leader Epoch 5 from offset 5. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,138] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,138] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,201] INFO [Partition pos-0 broker=0] Log loaded for partition pos-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,202] INFO [Partition pos-0 broker=0] pos-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,310] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 23 (kafka.cluster.Partition)
[2020-04-02 09:57:16,310] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 2 from offset 23. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,340] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,340] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,410] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,410] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 2 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,514] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,515] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,586] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 2 (kafka.cluster.Partition)
[2020-04-02 09:57:16,586] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 2 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,634] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,634] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,847] INFO starting (kafka.server.KafkaServer)
[2020-04-02 09:57:16,850] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-02 09:57:16,902] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,902] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,928] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:16,928] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:16,981] INFO [Partition hello-producer-topic-1 broker=0] Log loaded for partition hello-producer-topic-1 with initial high watermark 24 (kafka.cluster.Partition)
[2020-04-02 09:57:16,982] INFO [Partition hello-producer-topic-1 broker=0] hello-producer-topic-1 starts at Leader Epoch 4 from offset 24. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,039] INFO [Partition shipment-0 broker=0] Log loaded for partition shipment-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,042] INFO [Partition hello-producer-topic-3 broker=0] Log loaded for partition hello-producer-topic-3 with initial high watermark 36 (kafka.cluster.Partition)
[2020-04-02 09:57:17,045] INFO [Partition hello-producer-topic-4 broker=0] Log loaded for partition hello-producer-topic-4 with initial high watermark 20 (kafka.cluster.Partition)
[2020-04-02 09:57:17,049] INFO [Partition shipment-1 broker=0] Log loaded for partition shipment-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,055] INFO [Partition pos-2 broker=0] Log loaded for partition pos-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,059] INFO [Partition pos-1 broker=0] Log loaded for partition pos-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,079] INFO [Partition hadoop-sink-0 broker=0] Log loaded for partition hadoop-sink-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,089] INFO [Partition hadoop-sink-1 broker=0] Log loaded for partition hadoop-sink-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,100] INFO [Partition loyalty-1 broker=0] Log loaded for partition loyalty-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,119] INFO [Partition hello-producer-topic-0 broker=0] Log loaded for partition hello-producer-topic-0 with initial high watermark 11 (kafka.cluster.Partition)
[2020-04-02 09:57:17,150] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,152] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,153] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,154] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,154] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,154] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,154] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,154] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,174] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:17,194] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 31 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,207] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,208] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,225] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,236] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(hello-producer-topic-2, pos-0, loyalty-0, hello-producer-topic-1) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:17,238] INFO [Partition hello-producer-topic-2 broker=0] hello-producer-topic-2 starts at Leader Epoch 7 from offset 5. Previous Leader Epoch was: 5 (kafka.cluster.Partition)
[2020-04-02 09:57:17,275] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,276] INFO Client environment:host.name=DELL-PC (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,276] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,276] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,276] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,277] INFO Client environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,278] INFO Client environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:os.name=Windows 7 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:os.version=6.1 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:user.name=DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,279] INFO Client environment:user.home=C:\Users\DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,280] INFO Client environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-starter\11-pos-fanout\scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,280] INFO Client environment:os.memory.free=975MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,280] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,281] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,288] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@636be97c (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:17,301] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-02 09:57:17,311] INFO [Partition pos-0 broker=0] pos-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,315] INFO [GroupCoordinator 0]: Loading group metadata for HelloStreams with generation 7 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:17,316] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 91 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,318] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,319] INFO [Partition loyalty-0 broker=0] loyalty-0 starts at Leader Epoch 2 from offset 0. Previous Leader Epoch was: 0 (kafka.cluster.Partition)
[2020-04-02 09:57:17,324] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-13490 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:17,331] INFO [Partition hello-producer-topic-1 broker=0] hello-producer-topic-1 starts at Leader Epoch 6 from offset 24. Previous Leader Epoch was: 4 (kafka.cluster.Partition)
[2020-04-02 09:57:17,339] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,340] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,367] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-96857 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:17,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 27 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,367] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,368] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:17,400] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-02 09:57:17,431] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:17,453] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:17,598] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(hadoop-sink-0, hadoop-sink-1, hello-producer-topic-0, shipment-0, hello-producer-topic-3, hello-producer-topic-4, pos-1, pos-2, shipment-1, loyalty-1) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:17,598] INFO [Partition shipment-0 broker=0] shipment-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,625] INFO [Partition hello-producer-topic-3 broker=0] hello-producer-topic-3 starts at Leader Epoch 8 from offset 36. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,636] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:17,640] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:49482, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:17,699] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1000010c6a70001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:17,708] INFO [Partition hello-producer-topic-4 broker=0] hello-producer-topic-4 starts at Leader Epoch 7 from offset 20. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,715] INFO [Partition shipment-1 broker=0] shipment-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,721] INFO [Partition pos-2 broker=0] pos-2 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,728] INFO [Partition pos-1 broker=0] pos-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,740] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:17,886] INFO [Partition hadoop-sink-0 broker=0] hadoop-sink-0 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,895] INFO [Partition hadoop-sink-1 broker=0] hadoop-sink-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,901] INFO [Partition loyalty-1 broker=0] loyalty-1 starts at Leader Epoch 3 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:17,907] INFO [Partition hello-producer-topic-0 broker=0] hello-producer-topic-0 starts at Leader Epoch 8 from offset 11. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:19,733] INFO Cluster ID = uC5-M0G5Qy-3qM8_m3M3yQ (kafka.server.KafkaServer)
[2020-04-02 09:57:19,982] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9093
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:57:20,110] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9093
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:57:20,357] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:20,359] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:20,359] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:20,538] INFO Loading logs. (kafka.log.LogManager)
[2020-04-02 09:57:20,752] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-04-02 09:57:20,759] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:20,771] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,034] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,045] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 423 ms (kafka.log.Log)
[2020-04-02 09:57:21,100] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,100] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,112] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,115] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-04-02 09:57:21,128] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,128] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,167] INFO [ProducerStateManager partition=hello-producer-topic-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,217] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,221] INFO [ProducerStateManager partition=hello-producer-topic-0] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,227] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 105 ms (kafka.log.Log)
[2020-04-02 09:57:21,243] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,243] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,257] INFO [ProducerStateManager partition=hello-producer-topic-1] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,269] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,273] INFO [ProducerStateManager partition=hello-producer-topic-1] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-1\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,274] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 37 ms (kafka.log.Log)
[2020-04-02 09:57:21,285] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,285] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,296] INFO [ProducerStateManager partition=hello-producer-topic-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,307] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,310] INFO [ProducerStateManager partition=hello-producer-topic-2] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,311] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 32 ms (kafka.log.Log)
[2020-04-02 09:57:21,323] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,323] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,368] INFO [ProducerStateManager partition=hello-producer-topic-3] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,399] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,402] INFO [ProducerStateManager partition=hello-producer-topic-3] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-3\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,403] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 86 ms (kafka.log.Log)
[2020-04-02 09:57:21,416] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,417] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,430] INFO [ProducerStateManager partition=hello-producer-topic-4] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,467] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,471] INFO [ProducerStateManager partition=hello-producer-topic-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\hello-producer-topic-4\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,472] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 63 ms (kafka.log.Log)
[2020-04-02 09:57:21,485] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,485] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,499] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,503] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-04-02 09:57:21,517] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,517] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,538] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,542] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-04-02 09:57:21,554] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,554] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,565] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,569] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-04-02 09:57:21,585] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,585] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,601] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,604] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-04-02 09:57:21,617] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,617] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,629] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,639] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:21,650] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,651] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,676] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,680] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-04-02 09:57:21,698] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,698] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,712] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,716] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:21,728] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,728] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,746] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,750] INFO [Log partition=__consumer_offsets-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-04-02 09:57:21,769] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,770] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,821] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,824] INFO [Log partition=__consumer_offsets-12, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2020-04-02 09:57:21,837] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,837] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,859] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,863] INFO [Log partition=__consumer_offsets-15, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 34 ms (kafka.log.Log)
[2020-04-02 09:57:21,877] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,877] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,897] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,901] INFO [Log partition=__consumer_offsets-18, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-04-02 09:57:21,933] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,933] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,951] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,955] INFO [Log partition=__consumer_offsets-21, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-04-02 09:57:21,965] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:21,966] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,977] INFO [ProducerStateManager partition=__consumer_offsets-24] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,989] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:21,992] INFO [ProducerStateManager partition=__consumer_offsets-24] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-1\__consumer_offsets-24\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:21,993] INFO [Log partition=__consumer_offsets-24, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 34 ms (kafka.log.Log)
[2020-04-02 09:57:22,005] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,006] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,022] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,026] INFO [Log partition=__consumer_offsets-27, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:22,037] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,037] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,053] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,056] INFO [Log partition=__consumer_offsets-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-04-02 09:57:22,074] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,074] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,090] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,093] INFO [Log partition=__consumer_offsets-30, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-04-02 09:57:22,104] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,104] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,120] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,123] INFO [Log partition=__consumer_offsets-33, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-04-02 09:57:22,134] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,134] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,154] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,158] INFO [Log partition=__consumer_offsets-36, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-04-02 09:57:22,171] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,172] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,192] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,195] INFO [Log partition=__consumer_offsets-39, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-04-02 09:57:22,206] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,206] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,225] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,229] INFO [Log partition=__consumer_offsets-42, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:22,238] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,239] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,256] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,259] INFO [Log partition=__consumer_offsets-45, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2020-04-02 09:57:22,312] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,312] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,331] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,347] INFO [Log partition=__consumer_offsets-48, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-04-02 09:57:22,361] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,361] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,381] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,385] INFO [Log partition=__consumer_offsets-6, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:22,395] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:22,396] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,425] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:22,429] INFO [Log partition=__consumer_offsets-9, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[2020-04-02 09:57:22,467] INFO Logs loading complete in 1929 ms. (kafka.log.LogManager)
[2020-04-02 09:57:22,539] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-02 09:57:22,544] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-02 09:57:22,558] INFO starting (kafka.server.KafkaServer)
[2020-04-02 09:57:22,562] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-04-02 09:57:22,648] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:22,663] INFO Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,664] INFO Client environment:host.name=DELL-PC (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,664] INFO Client environment:java.version=1.8.0_221 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,664] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,664] INFO Client environment:java.home=C:\Program Files (x86)\Java\jdk1.8.0_221\jre (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,664] INFO Client environment:java.class.path=C:\kafka_2.13-2.4.0\libs\activation-1.1.1.jar;C:\kafka_2.13-2.4.0\libs\aopalliance-repackaged-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\argparse4j-0.7.0.jar;C:\kafka_2.13-2.4.0\libs\audience-annotations-0.5.0.jar;C:\kafka_2.13-2.4.0\libs\commons-cli-1.4.jar;C:\kafka_2.13-2.4.0\libs\commons-lang3-3.8.1.jar;C:\kafka_2.13-2.4.0\libs\connect-api-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-basic-auth-extension-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-file-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-json-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-mirror-client-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-runtime-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\connect-transforms-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\guava-20.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-api-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-locator-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\hk2-utils-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-core-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-databind-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-dataformat-csv-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-datatype-jdk8-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-base-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-jaxrs-json-provider-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-jaxb-annotations-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-paranamer-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jackson-module-scala_2.13-2.10.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.activation-api-1.2.1.jar;C:\kafka_2.13-2.4.0\libs\jakarta.annotation-api-1.3.4.jar;C:\kafka_2.13-2.4.0\libs\jakarta.inject-2.5.0.jar;C:\kafka_2.13-2.4.0\libs\jakarta.ws.rs-api-2.1.5.jar;C:\kafka_2.13-2.4.0\libs\jakarta.xml.bind-api-2.3.2.jar;C:\kafka_2.13-2.4.0\libs\javassist-3.22.0-CR2.jar;C:\kafka_2.13-2.4.0\libs\javax.servlet-api-3.1.0.jar;C:\kafka_2.13-2.4.0\libs\javax.ws.rs-api-2.1.1.jar;C:\kafka_2.13-2.4.0\libs\jaxb-api-2.3.0.jar;C:\kafka_2.13-2.4.0\libs\jersey-client-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-common-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-container-servlet-core-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-hk2-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-media-jaxb-2.28.jar;C:\kafka_2.13-2.4.0\libs\jersey-server-2.28.jar;C:\kafka_2.13-2.4.0\libs\jetty-client-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-continuation-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-http-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-io-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-security-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-server-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlet-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-servlets-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jetty-util-9.4.20.v20190813.jar;C:\kafka_2.13-2.4.0\libs\jopt-simple-5.0.4.jar;C:\kafka_2.13-2.4.0\libs\kafka-clients-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-log4j-appender-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-examples-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-scala_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-streams-test-utils-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka-tools-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-javadoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-scaladoc.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test-sources.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0-test.jar.asc;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar;C:\kafka_2.13-2.4.0\libs\kafka_2.13-2.4.0.jar.asc;C:\kafka_2.13-2.4.0\libs\log4j-1.2.17.jar;C:\kafka_2.13-2.4.0\libs\lz4-java-1.6.0.jar;C:\kafka_2.13-2.4.0\libs\maven-artifact-3.6.1.jar;C:\kafka_2.13-2.4.0\libs\metrics-core-2.2.0.jar;C:\kafka_2.13-2.4.0\libs\netty-buffer-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-codec-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-handler-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-resolver-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-epoll-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\netty-transport-native-unix-common-4.1.42.Final.jar;C:\kafka_2.13-2.4.0\libs\osgi-resource-locator-1.0.1.jar;C:\kafka_2.13-2.4.0\libs\paranamer-2.8.jar;C:\kafka_2.13-2.4.0\libs\plexus-utils-3.2.0.jar;C:\kafka_2.13-2.4.0\libs\reflections-0.9.11.jar;C:\kafka_2.13-2.4.0\libs\rocksdbjni-5.18.3.jar;C:\kafka_2.13-2.4.0\libs\scala-collection-compat_2.13-2.1.2.jar;C:\kafka_2.13-2.4.0\libs\scala-java8-compat_2.13-0.9.0.jar;C:\kafka_2.13-2.4.0\libs\scala-library-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\scala-logging_2.13-3.9.2.jar;C:\kafka_2.13-2.4.0\libs\scala-reflect-2.13.1.jar;C:\kafka_2.13-2.4.0\libs\slf4j-api-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\slf4j-log4j12-1.7.28.jar;C:\kafka_2.13-2.4.0\libs\snappy-java-1.1.7.3.jar;C:\kafka_2.13-2.4.0\libs\validation-api-2.0.1.Final.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zookeeper-jute-3.5.6.jar;C:\kafka_2.13-2.4.0\libs\zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:java.library.path=C:\Program Files (x86)\Java\jdk1.8.0_221\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;%JAVA_HOME\bin%;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\WINDOWS\System32;C:\kafka_2.13-2.4.0\bin\windows;C:\windows\system32\wbem;. (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:java.io.tmpdir=C:\Users\DELL\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:os.name=Windows 7 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:os.version=6.1 (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:user.name=DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,668] INFO Client environment:user.home=C:\Users\DELL (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,669] INFO Client environment:user.dir=E:\Kafka Learning Udemy\11-pos-fanout-starter\11-pos-fanout\scripts (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,669] INFO Client environment:os.memory.free=976MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,669] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,669] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,675] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@636be97c (org.apache.zookeeper.ZooKeeper)
[2020-04-02 09:57:22,689] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-04-02 09:57:22,737] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-04-02 09:57:22,754] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:22,763] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:22,811] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:22,815] INFO Socket connection established, initiating session, client: /127.0.0.1:49486, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:22,828] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000010c6a70002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:57:22,843] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-04-02 09:57:23,825] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2020-04-02 09:57:23,957] INFO [SocketServer brokerId=1] Created data-plane acceptor and processors for endpoint : EndPoint(null,9093,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-02 09:57:23,962] INFO [SocketServer brokerId=1] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-02 09:57:24,034] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:24,040] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:24,040] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:24,046] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:24,165] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-02 09:57:24,373] INFO Cluster ID = uC5-M0G5Qy-3qM8_m3M3yQ (kafka.server.KafkaServer)
[2020-04-02 09:57:24,442] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:24,489] INFO Stat of the created znode at /brokers/ids/1 is: 646,646,1585801644471,1585801644471,1,0,0,72057666090237953,184,0,646
 (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:24,491] INFO Registered broker 1 at path /brokers/ids/1 with addresses: ArraySeq(EndPoint(DELL-PC,9093,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 646 (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:24,721] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9094
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:57:24,788] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = C:/kafka_2.13-2.4.0/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9094
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-04-02 09:57:24,897] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:24,897] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:24,897] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:25,029] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:25,065] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:25,078] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:25,112] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:25,110] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-04-02 09:57:25,162] INFO [GroupMetadataManager brokerId=1] Removed 0 expired offsets in 17 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:25,201] INFO Loading logs. (kafka.log.LogManager)
[2020-04-02 09:57:25,218] INFO [ProducerId Manager 1]: Acquired new producerId block (brokerId:1,blockStartProducerId:10000,blockEndProducerId:10999) by writing to Zk with path version 11 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-02 09:57:25,363] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:57:25,384] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:57:25,395] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-02 09:57:25,438] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:25,461] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:25,565] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:25,657] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:25,664] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 331 ms (kafka.log.Log)
[2020-04-02 09:57:25,667] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-02 09:57:25,704] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:25,705] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:25,734] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:25,738] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 41 ms (kafka.log.Log)
[2020-04-02 09:57:25,755] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:25,756] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:25,811] INFO [SocketServer brokerId=1] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-02 09:57:25,814] INFO [ProducerStateManager partition=hello-producer-topic-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:25,836] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:25,836] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:25,837] INFO Kafka startTimeMs: 1585801645818 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:25,839] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2020-04-02 09:57:25,962] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:25,967] INFO [ProducerStateManager partition=hello-producer-topic-0] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-0\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:25,976] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 11 in 227 ms (kafka.log.Log)
[2020-04-02 09:57:25,988] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:25,988] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,052] INFO [ProducerStateManager partition=hello-producer-topic-1] Writing producer snapshot at offset 24 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,069] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 24 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,073] INFO [ProducerStateManager partition=hello-producer-topic-1] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-1\00000000000000000024.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,074] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 24 in 92 ms (kafka.log.Log)
[2020-04-02 09:57:26,090] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,091] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,105] INFO [ProducerStateManager partition=hello-producer-topic-2] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,203] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 5 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,207] INFO [ProducerStateManager partition=hello-producer-topic-2] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-2\00000000000000000005.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,207] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 5 in 123 ms (kafka.log.Log)
[2020-04-02 09:57:26,219] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,219] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,233] INFO [ProducerStateManager partition=hello-producer-topic-3] Writing producer snapshot at offset 36 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,245] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 36 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,249] INFO [ProducerStateManager partition=hello-producer-topic-3] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-3\00000000000000000036.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,250] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 36 in 37 ms (kafka.log.Log)
[2020-04-02 09:57:26,261] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,261] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,274] INFO [ProducerStateManager partition=hello-producer-topic-4] Writing producer snapshot at offset 20 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,286] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 20 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,289] INFO [ProducerStateManager partition=hello-producer-topic-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\hello-producer-topic-4\00000000000000000020.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,290] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 20 in 35 ms (kafka.log.Log)
[2020-04-02 09:57:26,306] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,306] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,316] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,324] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:26,346] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,346] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,356] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,360] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2020-04-02 09:57:26,402] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,403] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,415] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,419] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2020-04-02 09:57:26,436] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,436] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,447] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,450] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2020-04-02 09:57:26,461] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,462] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,694] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,697] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 243 ms (kafka.log.Log)
[2020-04-02 09:57:26,719] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,720] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,729] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,733] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 27 ms (kafka.log.Log)
[2020-04-02 09:57:26,752] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,753] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,781] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,788] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2020-04-02 09:57:26,803] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,804] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,833] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,837] INFO [Log partition=__consumer_offsets-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 45 ms (kafka.log.Log)
[2020-04-02 09:57:26,853] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,853] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,862] INFO [ProducerStateManager partition=__consumer_offsets-10] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,927] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,930] INFO [ProducerStateManager partition=__consumer_offsets-10] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\__consumer_offsets-10\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:26,945] INFO [Log partition=__consumer_offsets-10, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 100 ms (kafka.log.Log)
[2020-04-02 09:57:26,956] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:26,957] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,985] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:26,989] INFO [Log partition=__consumer_offsets-13, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 39 ms (kafka.log.Log)
[2020-04-02 09:57:26,999] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,000] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,021] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,024] INFO [Log partition=__consumer_offsets-16, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-04-02 09:57:27,044] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,045] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,060] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,063] INFO [Log partition=__consumer_offsets-19, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 35 ms (kafka.log.Log)
[2020-04-02 09:57:27,073] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,074] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,088] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,092] INFO [Log partition=__consumer_offsets-22, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2020-04-02 09:57:27,101] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,101] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,119] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,123] INFO [Log partition=__consumer_offsets-25, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:27,134] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,134] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,172] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,175] INFO [Log partition=__consumer_offsets-28, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2020-04-02 09:57:27,202] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,204] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,421] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,422] INFO [GroupCoordinator 0]: Member consumer-console-consumer-13490-1-79c43bfa-cc47-47db-b766-9572b3c99de8 in group console-consumer-13490 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:27,425] INFO [Log partition=__consumer_offsets-31, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 242 ms (kafka.log.Log)
[2020-04-02 09:57:27,435] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-13490 in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: removing member consumer-console-consumer-13490-1-79c43bfa-cc47-47db-b766-9572b3c99de8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:27,436] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,436] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,446] INFO [GroupCoordinator 0]: Group console-consumer-13490 with generation 2 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:27,461] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,465] INFO [Log partition=__consumer_offsets-34, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 36 ms (kafka.log.Log)
[2020-04-02 09:57:27,478] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,479] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,489] INFO [ProducerStateManager partition=__consumer_offsets-37] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:27,518] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,521] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\__consumer_offsets-37\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:27,522] INFO [Log partition=__consumer_offsets-37, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 50 ms (kafka.log.Log)
[2020-04-02 09:57:27,533] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,533] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,546] INFO [ProducerStateManager partition=__consumer_offsets-4] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-04-02 09:57:27,631] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,635] INFO [ProducerStateManager partition=__consumer_offsets-4] Loading producer state from snapshot file 'C:\kafka_2.13-2.4.0\data\kafka-2\__consumer_offsets-4\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2020-04-02 09:57:27,636] INFO [Log partition=__consumer_offsets-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 109 ms (kafka.log.Log)
[2020-04-02 09:57:27,661] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,661] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,687] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,695] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,699] INFO [Log partition=__consumer_offsets-40, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2020-04-02 09:57:27,708] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,708] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,721] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,724] INFO [Partition shipment-0 broker=1] Log loaded for partition shipment-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,782] INFO [Log partition=__consumer_offsets-43, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2020-04-02 09:57:27,790] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,790] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,809] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,809] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,813] INFO [Log partition=__consumer_offsets-46, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2020-04-02 09:57:27,815] INFO [Partition loyalty-0 broker=1] Log loaded for partition loyalty-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,824] INFO [Partition pos-1 broker=1] Log loaded for partition pos-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,825] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,825] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,829] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,839] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,843] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,844] INFO [Partition hello-producer-topic-2 broker=1] Log loaded for partition hello-producer-topic-2 with initial high watermark 5 (kafka.cluster.Partition)
[2020-04-02 09:57:27,847] INFO [Log partition=__consumer_offsets-49, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:27,853] INFO [Partition pos-2 broker=1] Log loaded for partition pos-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,857] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Recovering unflushed segment 0 (kafka.log.Log)
[2020-04-02 09:57:27,858] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,863] INFO [Partition hadoop-sink-1 broker=1] Log loaded for partition hadoop-sink-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,872] INFO [Partition loyalty-1 broker=1] Log loaded for partition loyalty-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:27,877] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-04-02 09:57:27,881] INFO [Log partition=__consumer_offsets-7, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-04-02 09:57:27,906] INFO Logs loading complete in 2704 ms. (kafka.log.LogManager)
[2020-04-02 09:57:27,953] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-04-02 09:57:27,956] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-04-02 09:57:27,996] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,001] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,060] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,082] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,091] INFO [Partition hello-producer-topic-3 broker=1] Log loaded for partition hello-producer-topic-3 with initial high watermark 36 (kafka.cluster.Partition)
[2020-04-02 09:57:28,101] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,121] INFO [Partition hadoop-sink-0 broker=1] Log loaded for partition hadoop-sink-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,137] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,219] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 2 (kafka.cluster.Partition)
[2020-04-02 09:57:28,237] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,244] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,248] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,262] INFO [Partition hello-producer-topic-0 broker=1] Log loaded for partition hello-producer-topic-0 with initial high watermark 11 (kafka.cluster.Partition)
[2020-04-02 09:57:28,267] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,274] INFO [Partition pos-0 broker=1] Log loaded for partition pos-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,278] INFO [Partition hello-producer-topic-4 broker=1] Log loaded for partition hello-producer-topic-4 with initial high watermark 20 (kafka.cluster.Partition)
[2020-04-02 09:57:28,288] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,293] INFO [Partition shipment-1 broker=1] Log loaded for partition shipment-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,297] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:28,304] INFO [Partition hello-producer-topic-1 broker=1] Log loaded for partition hello-producer-topic-1 with initial high watermark 24 (kafka.cluster.Partition)
[2020-04-02 09:57:28,307] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(hadoop-sink-0, shipment-0, shipment-1, loyalty-0, hadoop-sink-1, loyalty-1, hello-producer-topic-4, hello-producer-topic-3, hello-producer-topic-2, hello-producer-topic-1, hello-producer-topic-0, pos-2, pos-0, pos-1) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:28,404] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,483] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker BrokerEndPoint(id=0, host=DELL-PC:9092) for partitions HashMap(hadoop-sink-0 -> (offset=0, leaderEpoch=3), hadoop-sink-1 -> (offset=0, leaderEpoch=3), hello-producer-topic-0 -> (offset=11, leaderEpoch=8), hello-producer-topic-2 -> (offset=5, leaderEpoch=7), loyalty-0 -> (offset=0, leaderEpoch=2), pos-0 -> (offset=0, leaderEpoch=2), shipment-0 -> (offset=0, leaderEpoch=3), hello-producer-topic-1 -> (offset=24, leaderEpoch=6), hello-producer-topic-3 -> (offset=36, leaderEpoch=8), hello-producer-topic-4 -> (offset=20, leaderEpoch=7), pos-1 -> (offset=0, leaderEpoch=3), pos-2 -> (offset=0, leaderEpoch=3), shipment-1 -> (offset=0, leaderEpoch=3), loyalty-1 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:28,589] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2020-04-02 09:57:28,616] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 20 has no effect as the largest offset in the log is 19 (kafka.log.Log)
[2020-04-02 09:57:28,617] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 36 has no effect as the largest offset in the log is 35 (kafka.log.Log)
[2020-04-02 09:57:28,617] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2020-04-02 09:57:28,618] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 24 has no effect as the largest offset in the log is 23 (kafka.log.Log)
[2020-04-02 09:57:28,628] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition hadoop-sink-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,629] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,630] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition shipment-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,630] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,630] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition pos-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,630] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,630] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition shipment-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,631] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,631] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition pos-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,631] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,631] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition pos-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,631] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,633] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition loyalty-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,633] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,633] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition hadoop-sink-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,633] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,634] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition loyalty-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:28,634] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:28,780] INFO [Partition hadoop-sink-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,791] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-36, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-39, __consumer_offsets-12) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:28,797] INFO [Partition __consumer_offsets-3 broker=1] __consumer_offsets-3 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,848] INFO [Partition hadoop-sink-0 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:28,852] INFO [Partition hadoop-sink-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,863] INFO [Partition __consumer_offsets-18 broker=1] __consumer_offsets-18 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,898] INFO [Partition __consumer_offsets-39 broker=1] __consumer_offsets-39 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,904] INFO [Partition hadoop-sink-1 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:28,905] INFO [Partition hello-producer-topic-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,924] INFO [Partition __consumer_offsets-9 broker=1] __consumer_offsets-9 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,926] INFO [Partition hello-producer-topic-0 broker=0] ISR updated to [0,1] and zkVersion updated to [12] (kafka.cluster.Partition)
[2020-04-02 09:57:28,926] INFO [Partition hello-producer-topic-2 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,931] INFO [Partition hello-producer-topic-2 broker=0] ISR updated to [0,1] and zkVersion updated to [11] (kafka.cluster.Partition)
[2020-04-02 09:57:28,932] INFO [Partition hello-producer-topic-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,934] INFO [Partition __consumer_offsets-24 broker=1] __consumer_offsets-24 starts at Leader Epoch 4 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,937] INFO [Partition hello-producer-topic-1 broker=0] ISR updated to [0,1] and zkVersion updated to [10] (kafka.cluster.Partition)
[2020-04-02 09:57:28,938] INFO [Partition hello-producer-topic-3 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,942] INFO [Partition __consumer_offsets-27 broker=1] __consumer_offsets-27 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,951] INFO [Partition __consumer_offsets-42 broker=1] __consumer_offsets-42 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,959] INFO [Partition __consumer_offsets-12 broker=1] __consumer_offsets-12 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,960] INFO [Partition hello-producer-topic-3 broker=0] ISR updated to [0,1] and zkVersion updated to [12] (kafka.cluster.Partition)
[2020-04-02 09:57:28,960] INFO [Partition hello-producer-topic-4 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,976] INFO [Partition hello-producer-topic-4 broker=0] ISR updated to [0,1] and zkVersion updated to [11] (kafka.cluster.Partition)
[2020-04-02 09:57:28,976] INFO [Partition __consumer_offsets-33 broker=1] __consumer_offsets-33 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,976] INFO [Partition loyalty-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,982] INFO [Partition __consumer_offsets-48 broker=1] __consumer_offsets-48 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,987] INFO [Partition loyalty-0 broker=0] ISR updated to [0,1] and zkVersion updated to [3] (kafka.cluster.Partition)
[2020-04-02 09:57:28,988] INFO [Partition loyalty-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:28,989] INFO [Partition __consumer_offsets-21 broker=1] __consumer_offsets-21 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,009] INFO [Partition __consumer_offsets-36 broker=1] __consumer_offsets-36 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,016] INFO [Partition __consumer_offsets-6 broker=1] __consumer_offsets-6 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,022] INFO [Partition __consumer_offsets-45 broker=1] __consumer_offsets-45 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,027] INFO [Partition __consumer_offsets-15 broker=1] __consumer_offsets-15 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,033] INFO [Partition __consumer_offsets-30 broker=1] __consumer_offsets-30 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,039] INFO [Partition __consumer_offsets-0 broker=1] __consumer_offsets-0 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,043] INFO [Partition loyalty-1 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:29,046] INFO [Partition pos-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,057] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,059] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,060] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,061] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,061] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,061] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,061] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,071] INFO [Partition pos-0 broker=0] ISR updated to [0,1] and zkVersion updated to [3] (kafka.cluster.Partition)
[2020-04-02 09:57:29,072] INFO [Partition pos-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,086] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-3 in 26 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,093] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,093] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,094] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,094] INFO [Partition pos-1 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:29,094] INFO [Partition pos-2 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,119] INFO [Partition pos-2 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:29,120] INFO [Partition shipment-0 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,125] INFO [Partition shipment-0 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:29,125] INFO [Partition shipment-1 broker=0] Expanding ISR from 0 to 0,1 (kafka.cluster.Partition)
[2020-04-02 09:57:29,140] INFO [Partition shipment-1 broker=0] ISR updated to [0,1] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:29,156] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2020-04-02 09:57:29,167] INFO [GroupCoordinator 1]: Loading group metadata for console-consumer-17735 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:29,169] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 75 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,172] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-27 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,173] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,173] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,173] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,173] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,174] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,174] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,174] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,175] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,175] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,175] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,176] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:29,288] INFO [SocketServer brokerId=2] Created data-plane acceptor and processors for endpoint : EndPoint(null,9094,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-04-02 09:57:29,291] INFO [SocketServer brokerId=2] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-04-02 09:57:29,346] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:29,360] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:29,361] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:29,362] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:29,438] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-04-02 09:57:29,671] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:29,720] INFO Stat of the created znode at /brokers/ids/2 is: 679,679,1585801649703,1585801649703,1,0,0,72057666090237954,184,0,679
 (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:29,727] INFO Registered broker 2 at path /brokers/ids/2 with addresses: ArraySeq(EndPoint(DELL-PC,9094,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 679 (kafka.zk.KafkaZkClient)
[2020-04-02 09:57:30,089] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:30,093] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:30,117] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:30,119] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:30,121] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:30,147] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 21 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:30,246] INFO [ProducerId Manager 2]: Acquired new producerId block (brokerId:2,blockStartProducerId:11000,blockEndProducerId:11999) by writing to Zk with path version 12 (kafka.coordinator.transaction.ProducerIdManager)
[2020-04-02 09:57:30,337] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:57:30,343] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-04-02 09:57:30,352] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-04-02 09:57:30,409] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-04-02 09:57:30,499] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-04-02 09:57:30,705] INFO [SocketServer brokerId=2] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-04-02 09:57:30,727] INFO Kafka version: 2.4.0 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:30,727] INFO Kafka commitId: 77a89fcf8d7fa018 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:30,727] INFO Kafka startTimeMs: 1585801650706 (org.apache.kafka.common.utils.AppInfoParser)
[2020-04-02 09:57:30,730] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2020-04-02 09:57:31,261] INFO [Partition shipment-0 broker=2] Log loaded for partition shipment-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,271] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,325] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,338] INFO [Partition loyalty-0 broker=2] Log loaded for partition loyalty-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,343] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,349] INFO [Partition pos-1 broker=2] Log loaded for partition pos-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,355] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,360] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,364] INFO [Partition hello-producer-topic-2 broker=2] Log loaded for partition hello-producer-topic-2 with initial high watermark 5 (kafka.cluster.Partition)
[2020-04-02 09:57:31,371] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,384] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 2 (kafka.cluster.Partition)
[2020-04-02 09:57:31,389] INFO [Partition pos-2 broker=2] Log loaded for partition pos-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,397] INFO [Partition hadoop-sink-1 broker=2] Log loaded for partition hadoop-sink-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,409] INFO [Partition loyalty-1 broker=2] Log loaded for partition loyalty-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,414] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,419] INFO [Partition hello-producer-topic-3 broker=2] Log loaded for partition hello-producer-topic-3 with initial high watermark 36 (kafka.cluster.Partition)
[2020-04-02 09:57:31,426] INFO [Partition hadoop-sink-0 broker=2] Log loaded for partition hadoop-sink-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,435] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,445] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,448] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,452] INFO [Partition hello-producer-topic-0 broker=2] Log loaded for partition hello-producer-topic-0 with initial high watermark 11 (kafka.cluster.Partition)
[2020-04-02 09:57:31,457] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,462] INFO [Partition pos-0 broker=2] Log loaded for partition pos-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,467] INFO [Partition hello-producer-topic-4 broker=2] Log loaded for partition hello-producer-topic-4 with initial high watermark 20 (kafka.cluster.Partition)
[2020-04-02 09:57:31,472] INFO [Partition shipment-1 broker=2] Log loaded for partition shipment-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,480] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,485] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,495] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,500] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,506] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-04-02 09:57:31,513] INFO [Partition hello-producer-topic-1 broker=2] Log loaded for partition hello-producer-topic-1 with initial high watermark 24 (kafka.cluster.Partition)
[2020-04-02 09:57:31,516] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(hadoop-sink-0, shipment-0, shipment-1, loyalty-0, hadoop-sink-1, loyalty-1, hello-producer-topic-4, hello-producer-topic-3, hello-producer-topic-2, hello-producer-topic-1, hello-producer-topic-0, pos-2, pos-0, pos-1) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:31,616] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:31,629] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=DELL-PC:9092) for partitions HashMap(hadoop-sink-0 -> (offset=0, leaderEpoch=3), hadoop-sink-1 -> (offset=0, leaderEpoch=3), hello-producer-topic-0 -> (offset=11, leaderEpoch=8), hello-producer-topic-2 -> (offset=5, leaderEpoch=7), loyalty-0 -> (offset=0, leaderEpoch=2), pos-0 -> (offset=0, leaderEpoch=2), shipment-0 -> (offset=0, leaderEpoch=3), hello-producer-topic-1 -> (offset=24, leaderEpoch=6), hello-producer-topic-3 -> (offset=36, leaderEpoch=8), hello-producer-topic-4 -> (offset=20, leaderEpoch=7), pos-1 -> (offset=0, leaderEpoch=3), pos-2 -> (offset=0, leaderEpoch=3), shipment-1 -> (offset=0, leaderEpoch=3), loyalty-1 -> (offset=0, leaderEpoch=3)) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:31,798] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-7, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-04-02 09:57:31,806] INFO [Partition __consumer_offsets-37 broker=2] __consumer_offsets-37 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,869] INFO [Partition __consumer_offsets-7 broker=2] __consumer_offsets-7 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,902] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,911] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 4 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,918] INFO [Partition __consumer_offsets-31 broker=2] __consumer_offsets-31 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,927] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,934] INFO [Partition __consumer_offsets-1 broker=2] __consumer_offsets-1 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,941] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,950] INFO [Partition __consumer_offsets-19 broker=2] __consumer_offsets-19 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,956] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,961] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 4 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,967] INFO [Partition __consumer_offsets-25 broker=2] __consumer_offsets-25 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,973] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,978] INFO [Partition __consumer_offsets-43 broker=2] __consumer_offsets-43 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,984] INFO [Partition __consumer_offsets-13 broker=2] __consumer_offsets-13 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,989] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:31,995] INFO [Partition __consumer_offsets-49 broker=2] __consumer_offsets-49 starts at Leader Epoch 4 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2020-04-02 09:57:32,009] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,011] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,011] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,011] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,012] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,013] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,013] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,013] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,013] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,013] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,013] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,014] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,014] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,014] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,014] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,014] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,015] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,095] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-46600 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:32,115] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 102 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,116] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,117] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,123] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-38413 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:32,124] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 7 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,125] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,126] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,127] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,127] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,127] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,128] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,136] INFO [GroupCoordinator 2]: Loading group metadata for console-consumer-31216 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:32,136] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,137] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,137] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,137] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,138] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,138] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,138] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-04-02 09:57:32,691] INFO [Log partition=hello-producer-topic-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 11 has no effect as the largest offset in the log is 10 (kafka.log.Log)
[2020-04-02 09:57:32,695] INFO [Log partition=hello-producer-topic-4, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 20 has no effect as the largest offset in the log is 19 (kafka.log.Log)
[2020-04-02 09:57:32,698] INFO [Log partition=hello-producer-topic-3, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 36 has no effect as the largest offset in the log is 35 (kafka.log.Log)
[2020-04-02 09:57:32,698] INFO [Log partition=hello-producer-topic-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 5 has no effect as the largest offset in the log is 4 (kafka.log.Log)
[2020-04-02 09:57:32,698] INFO [Log partition=hello-producer-topic-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 24 has no effect as the largest offset in the log is 23 (kafka.log.Log)
[2020-04-02 09:57:32,704] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition hadoop-sink-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,704] INFO [Log partition=hadoop-sink-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,704] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition shipment-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,704] INFO [Log partition=shipment-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,705] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition pos-2 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,705] INFO [Log partition=pos-2, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,705] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition shipment-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,705] INFO [Log partition=shipment-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,705] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition pos-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,706] INFO [Log partition=pos-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,706] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition pos-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,706] INFO [Log partition=pos-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,706] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition loyalty-0 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,706] INFO [Log partition=loyalty-0, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,706] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition hadoop-sink-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,706] INFO [Log partition=hadoop-sink-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,706] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition loyalty-1 to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2020-04-02 09:57:32,707] INFO [Log partition=loyalty-1, dir=C:\kafka_2.13-2.4.0\data\kafka-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.Log)
[2020-04-02 09:57:32,716] INFO [Partition hadoop-sink-0 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,735] INFO [Partition hadoop-sink-0 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:32,735] INFO [Partition hadoop-sink-1 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,739] INFO [Partition hadoop-sink-1 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:32,740] INFO [Partition hello-producer-topic-0 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,745] INFO [Partition hello-producer-topic-0 broker=0] ISR updated to [0,1,2] and zkVersion updated to [13] (kafka.cluster.Partition)
[2020-04-02 09:57:32,745] INFO [Partition hello-producer-topic-2 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,752] INFO [Partition hello-producer-topic-2 broker=0] ISR updated to [0,1,2] and zkVersion updated to [12] (kafka.cluster.Partition)
[2020-04-02 09:57:32,752] INFO [Partition hello-producer-topic-1 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,760] INFO [Partition hello-producer-topic-1 broker=0] ISR updated to [0,1,2] and zkVersion updated to [11] (kafka.cluster.Partition)
[2020-04-02 09:57:32,760] INFO [Partition hello-producer-topic-3 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,764] INFO [Partition hello-producer-topic-3 broker=0] ISR updated to [0,1,2] and zkVersion updated to [13] (kafka.cluster.Partition)
[2020-04-02 09:57:32,765] INFO [Partition hello-producer-topic-4 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,769] INFO [Partition hello-producer-topic-4 broker=0] ISR updated to [0,1,2] and zkVersion updated to [12] (kafka.cluster.Partition)
[2020-04-02 09:57:32,769] INFO [Partition loyalty-0 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,773] INFO [Partition loyalty-0 broker=0] ISR updated to [0,1,2] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:32,773] INFO [Partition loyalty-1 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,777] INFO [Partition loyalty-1 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:32,778] INFO [Partition pos-0 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,782] INFO [Partition pos-0 broker=0] ISR updated to [0,1,2] and zkVersion updated to [4] (kafka.cluster.Partition)
[2020-04-02 09:57:32,782] INFO [Partition pos-1 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,786] INFO [Partition pos-1 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:32,786] INFO [Partition pos-2 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,791] INFO [Partition pos-2 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:32,791] INFO [Partition shipment-0 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,796] INFO [Partition shipment-0 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:32,797] INFO [Partition shipment-1 broker=0] Expanding ISR from 0,1 to 0,1,2 (kafka.cluster.Partition)
[2020-04-02 09:57:32,804] INFO [Partition shipment-1 broker=0] ISR updated to [0,1,2] and zkVersion updated to [5] (kafka.cluster.Partition)
[2020-04-02 09:57:42,323] INFO [GroupCoordinator 2]: Member consumer-console-consumer-46600-1-bd2b8a0d-6ac4-4550-945f-d3ae5f929cd8 in group console-consumer-46600 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:42,339] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-46600 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member consumer-console-consumer-46600-1-bd2b8a0d-6ac4-4550-945f-d3ae5f929cd8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:42,347] INFO [GroupCoordinator 2]: Group console-consumer-46600 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:42,897] INFO [GroupCoordinator 2]: Member consumer-console-consumer-38413-1-5bedf988-9285-4983-a684-f4380f6fde39 in group console-consumer-38413 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:42,897] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-38413 in state PreparingRebalance with old generation 1 (__consumer_offsets-10) (reason: removing member consumer-console-consumer-38413-1-5bedf988-9285-4983-a684-f4380f6fde39 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:42,897] INFO [GroupCoordinator 2]: Group console-consumer-38413 with generation 2 is now empty (__consumer_offsets-10) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:43,387] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-55081 in state PreparingRebalance with old generation 0 (__consumer_offsets-0) (reason: Adding new member consumer-console-consumer-55081-1-2943f607-d457-4b41-9c79-37091d3382c3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:43,429] INFO [GroupCoordinator 1]: Stabilized group console-consumer-55081 generation 1 (__consumer_offsets-0) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:43,472] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-55081 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:47,713] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-3349 in state PreparingRebalance with old generation 0 (__consumer_offsets-38) (reason: Adding new member consumer-console-consumer-3349-1-24e7d48c-21e8-49e0-96b8-a2bcdcb39a62 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:47,725] INFO [GroupCoordinator 0]: Stabilized group console-consumer-3349 generation 1 (__consumer_offsets-38) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:47,781] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-3349 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:53,779] INFO [GroupCoordinator 1]: Preparing to rebalance group console-consumer-70662 in state PreparingRebalance with old generation 0 (__consumer_offsets-42) (reason: Adding new member consumer-console-consumer-70662-1-c9e84f03-bc81-4edb-bb97-78015790b8de with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:53,783] INFO [GroupCoordinator 1]: Stabilized group console-consumer-70662 generation 1 (__consumer_offsets-42) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:57:53,811] INFO [GroupCoordinator 1]: Assignment received from leader for group console-consumer-70662 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:58:13,938] INFO [GroupCoordinator 1]: Preparing to rebalance group PosFanout in state PreparingRebalance with old generation 0 (__consumer_offsets-15) (reason: Adding new member PosFanout-8c9ccc34-5670-46c9-8319-6c90b31e3b17-StreamThread-1-consumer-d5f9643c-e8c7-4b9d-a60b-16cc153a48d5 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:58:13,941] INFO [GroupCoordinator 1]: Stabilized group PosFanout generation 1 (__consumer_offsets-15) (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:58:13,995] INFO [GroupCoordinator 1]: Assignment received from leader for group PosFanout for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-04-02 09:59:11,745] WARN Client session timed out, have not heard from server in 4000ms for sessionid 0x1000010c6a70002 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:59:11,745] INFO Client session timed out, have not heard from server in 4000ms for sessionid 0x1000010c6a70002, closing socket connection and attempting reconnect (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:59:11,868] WARN Unable to read additional data from client sessionid 0x1000010c6a70002, likely client has closed socket (org.apache.zookeeper.server.NIOServerCnxn)
[2020-04-02 09:59:13,237] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:59:13,238] INFO Socket connection established, initiating session, client: /127.0.0.1:49585, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:59:13,348] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000010c6a70002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-04-02 09:59:37,924] WARN Exception causing close of session 0x1000010c6a70002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-04-02 09:59:37,925] WARN Exception causing close of session 0x1000010c6a70000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2020-04-02 09:59:37,943] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=182397819, epoch=680) to node 0: {}. (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:107)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:196)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:39)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:286)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:133)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:132)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:114)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2020-04-02 09:59:37,974] WARN [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=1, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={hadoop-sink-0=(fetchOffset=7039, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), hadoop-sink-1=(fetchOffset=16472, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), loyalty-0=(fetchOffset=1253, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), loyalty-1=(fetchOffset=2913, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), pos-0=(fetchOffset=2434, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[2]), pos-2=(fetchOffset=3839, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), shipment-0=(fetchOffset=1777, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3]), shipment-1=(fetchOffset=3575, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[3])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=182397819, epoch=680), rackId=) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 0 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:107)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:196)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:39)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:286)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:133)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:132)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:114)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
