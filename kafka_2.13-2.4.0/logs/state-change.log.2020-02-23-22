[2020-02-23 21:33:43,398] DEBUG preRegister called. Server=com.sun.jmx.mbeanserver.JmxMBeanServer@66d3c617, name=log4j:logger=state.change.logger (state.change.logger)
[2020-02-23 22:00:40,732] TRACE [Controller id=0 epoch=1] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 0 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:11:33,868] TRACE [Controller id=0 epoch=1] Changed partition myfirst-0 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2020-02-23 22:11:33,869] TRACE [Controller id=0 epoch=1] Changed partition myfirst-1 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2020-02-23 22:11:33,869] TRACE [Controller id=0 epoch=1] Changed partition myfirst-2 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2020-02-23 22:11:33,882] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition myfirst-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-02-23 22:11:33,882] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition myfirst-1 from NonExistentReplica to NewReplica (state.change.logger)
[2020-02-23 22:11:33,883] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition myfirst-2 from NonExistentReplica to NewReplica (state.change.logger)
[2020-02-23 22:11:33,972] TRACE [Controller id=0 epoch=1] Changed partition myfirst-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger)
[2020-02-23 22:11:33,972] TRACE [Controller id=0 epoch=1] Changed partition myfirst-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger)
[2020-02-23 22:11:33,972] TRACE [Controller id=0 epoch=1] Changed partition myfirst-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger)
[2020-02-23 22:11:33,976] TRACE [Controller id=0 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) to broker 0 for partition myfirst-2 (state.change.logger)
[2020-02-23 22:11:33,976] TRACE [Controller id=0 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) to broker 0 for partition myfirst-1 (state.change.logger)
[2020-02-23 22:11:33,976] TRACE [Controller id=0 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) to broker 0 for partition myfirst-0 (state.change.logger)
[2020-02-23 22:11:33,982] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition myfirst-2 (state.change.logger)
[2020-02-23 22:11:33,983] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition myfirst-1 (state.change.logger)
[2020-02-23 22:11:33,983] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition myfirst-0 (state.change.logger)
[2020-02-23 22:11:33,985] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition myfirst-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:11:33,985] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition myfirst-1 from NewReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:11:33,985] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition myfirst-2 from NewReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:11:34,074] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 1 from controller 0 epoch 1 (state.change.logger)
[2020-02-23 22:11:34,074] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 1 from controller 0 epoch 1 (state.change.logger)
[2020-02-23 22:11:34,074] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 1 from controller 0 epoch 1 (state.change.logger)
[2020-02-23 22:11:34,158] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 1 starting the become-leader transition for partition myfirst-0 (state.change.logger)
[2020-02-23 22:11:34,158] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 1 starting the become-leader transition for partition myfirst-1 (state.change.logger)
[2020-02-23 22:11:34,158] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 1 starting the become-leader transition for partition myfirst-2 (state.change.logger)
[2020-02-23 22:11:34,526] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 1 for partition myfirst-0 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:11:34,555] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 1 for partition myfirst-1 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:11:34,589] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 1 for partition myfirst-2 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:11:34,591] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 1 for the become-leader transition for partition myfirst-0 (state.change.logger)
[2020-02-23 22:11:34,592] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 1 for the become-leader transition for partition myfirst-1 (state.change.logger)
[2020-02-23 22:11:34,592] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 1 for the become-leader transition for partition myfirst-2 (state.change.logger)
[2020-02-23 22:11:34,615] TRACE [Controller id=0 epoch=1] Received response {error_code=0,partition_errors=[{topic_name=myfirst,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=myfirst,partition_index=1,error_code=0,_tagged_fields={}},{topic_name=myfirst,partition_index=0,error_code=0,_tagged_fields={}}],_tagged_fields={}} for request LEADER_AND_ISR with correlation id 1 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:11:34,629] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition myfirst-2 in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2 (state.change.logger)
[2020-02-23 22:11:34,629] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition myfirst-1 in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2 (state.change.logger)
[2020-02-23 22:11:34,630] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition myfirst-0 in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 2 (state.change.logger)
[2020-02-23 22:11:34,631] TRACE [Controller id=0 epoch=1] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 2 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:12:22,944] TRACE [Controller id=0 epoch=1] Changed partition mysecond-0 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2020-02-23 22:12:22,944] TRACE [Controller id=0 epoch=1] Changed partition mysecond-1 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2020-02-23 22:12:22,944] TRACE [Controller id=0 epoch=1] Changed partition mysecond-2 state from NonExistentPartition to NewPartition with assigned replicas 0 (state.change.logger)
[2020-02-23 22:12:22,945] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-0 from NonExistentReplica to NewReplica (state.change.logger)
[2020-02-23 22:12:22,946] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-1 from NonExistentReplica to NewReplica (state.change.logger)
[2020-02-23 22:12:22,946] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-2 from NonExistentReplica to NewReplica (state.change.logger)
[2020-02-23 22:12:23,000] TRACE [Controller id=0 epoch=1] Changed partition mysecond-0 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger)
[2020-02-23 22:12:23,001] TRACE [Controller id=0 epoch=1] Changed partition mysecond-1 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger)
[2020-02-23 22:12:23,001] TRACE [Controller id=0 epoch=1] Changed partition mysecond-2 from NewPartition to OnlinePartition with state LeaderAndIsr(leader=0, leaderEpoch=0, isr=List(0), zkVersion=0) (state.change.logger)
[2020-02-23 22:12:23,001] TRACE [Controller id=0 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) to broker 0 for partition mysecond-2 (state.change.logger)
[2020-02-23 22:12:23,001] TRACE [Controller id=0 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) to broker 0 for partition mysecond-0 (state.change.logger)
[2020-02-23 22:12:23,001] TRACE [Controller id=0 epoch=1] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) to broker 0 for partition mysecond-1 (state.change.logger)
[2020-02-23 22:12:23,002] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:12:23,002] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:12:23,002] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:12:23,003] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-0 from NewReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:12:23,003] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-1 from NewReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:12:23,003] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-2 from NewReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:12:23,004] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 3 from controller 0 epoch 1 (state.change.logger)
[2020-02-23 22:12:23,004] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 3 from controller 0 epoch 1 (state.change.logger)
[2020-02-23 22:12:23,004] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=true) correlation id 3 from controller 0 epoch 1 (state.change.logger)
[2020-02-23 22:12:23,017] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 epoch 1 starting the become-leader transition for partition mysecond-0 (state.change.logger)
[2020-02-23 22:12:23,017] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 epoch 1 starting the become-leader transition for partition mysecond-2 (state.change.logger)
[2020-02-23 22:12:23,017] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 3 from controller 0 epoch 1 starting the become-leader transition for partition mysecond-1 (state.change.logger)
[2020-02-23 22:12:23,055] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 3 for partition mysecond-0 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:12:23,085] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 3 for partition mysecond-2 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:12:23,111] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 1 with correlation id 3 for partition mysecond-1 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:12:23,111] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 3 from controller 0 epoch 1 for the become-leader transition for partition mysecond-0 (state.change.logger)
[2020-02-23 22:12:23,112] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 3 from controller 0 epoch 1 for the become-leader transition for partition mysecond-2 (state.change.logger)
[2020-02-23 22:12:23,112] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 3 from controller 0 epoch 1 for the become-leader transition for partition mysecond-1 (state.change.logger)
[2020-02-23 22:12:23,115] TRACE [Controller id=0 epoch=1] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=0,_tagged_fields={}}],_tagged_fields={}} for request LEADER_AND_ISR with correlation id 3 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:12:23,118] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition mysecond-2 in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4 (state.change.logger)
[2020-02-23 22:12:23,118] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition mysecond-0 in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4 (state.change.logger)
[2020-02-23 22:12:23,118] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition mysecond-1 in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 4 (state.change.logger)
[2020-02-23 22:12:23,119] TRACE [Controller id=0 epoch=1] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 4 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:15:40,382] TRACE [Controller id=0 epoch=1] Changed partition mysecond-0 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-02-23 22:15:40,383] TRACE [Controller id=0 epoch=1] Changed partition mysecond-1 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-02-23 22:15:40,383] TRACE [Controller id=0 epoch=1] Changed partition mysecond-2 state from OnlinePartition to OfflinePartition (state.change.logger)
[2020-02-23 22:15:40,385] TRACE [Controller id=0 epoch=1] Changed partition mysecond-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-02-23 22:15:40,385] TRACE [Controller id=0 epoch=1] Changed partition mysecond-1 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-02-23 22:15:40,385] TRACE [Controller id=0 epoch=1] Changed partition mysecond-2 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-02-23 22:15:40,387] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:15:40,387] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:15:40,387] TRACE [Controller id=0 epoch=1] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:15:40,394] TRACE [Broker id=0] Deleted partition mysecond-2 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 5 (state.change.logger)
[2020-02-23 22:15:40,394] TRACE [Broker id=0] Deleted partition mysecond-0 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 5 (state.change.logger)
[2020-02-23 22:15:40,395] TRACE [Broker id=0] Deleted partition mysecond-1 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 1 with correlation id 5 (state.change.logger)
[2020-02-23 22:15:40,399] TRACE [Controller id=0 epoch=1] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 5 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:15:40,483] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-2 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-02-23 22:15:40,483] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-02-23 22:15:40,483] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-1 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-02-23 22:15:40,492] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-02-23 22:15:40,492] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-1 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-02-23 22:15:40,492] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-2 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-02-23 22:15:40,516] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:15:40,521] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:15:40,521] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:15:40,521] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:15:40,521] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:15:40,521] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:15:40,528] TRACE [Controller id=0 epoch=1] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=0,_tagged_fields={}}],_tagged_fields={}} for request STOP_REPLICA with correlation id 6 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:15:40,533] TRACE [Broker id=0] Handling stop replica (delete=true) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:15:40,612] ERROR [Broker id=0] Ignoring stop replica (delete=true) for partition mysecond-0 due to storage exception (state.change.logger)
org.apache.kafka.common.errors.KafkaStorageException: Error while renaming dir for mysecond-0 in log dir C:\kafka_2.13-2.4.0\data\kafka
Caused by: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-0 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-0.c0e7d681029243f6a7ff22c2ebc80878-delete
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:966)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2316)
	at kafka.log.Log.renameDir(Log.scala:964)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:925)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:479)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:470)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:360)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:404)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:206)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:402)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:131)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:70)
	at java.lang.Thread.run(Thread.java:748)
	Suppressed: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-0 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-0.c0e7d681029243f6a7ff22c2ebc80878-delete
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-02-23 22:15:40,613] TRACE [Broker id=0] Handling stop replica (delete=true) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:15:40,647] ERROR [Broker id=0] Ignoring stop replica (delete=true) for partition mysecond-1 due to storage exception (state.change.logger)
org.apache.kafka.common.errors.KafkaStorageException: Error while renaming dir for mysecond-1 in log dir C:\kafka_2.13-2.4.0\data\kafka
Caused by: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-1 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-1.7eaec42e36724e43909e8aeb4a2bf433-delete
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:966)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2316)
	at kafka.log.Log.renameDir(Log.scala:964)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:925)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:479)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:470)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:360)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:404)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:206)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:402)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:131)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:70)
	at java.lang.Thread.run(Thread.java:748)
	Suppressed: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-1 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-1.7eaec42e36724e43909e8aeb4a2bf433-delete
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-02-23 22:15:40,649] TRACE [Broker id=0] Handling stop replica (delete=true) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:15:40,667] ERROR [Broker id=0] Ignoring stop replica (delete=true) for partition mysecond-2 due to storage exception (state.change.logger)
org.apache.kafka.common.errors.KafkaStorageException: Error while renaming dir for mysecond-2 in log dir C:\kafka_2.13-2.4.0\data\kafka
Caused by: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-2 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-2.9f75731fb4994123999d8ae0782ca8db-delete
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:966)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2316)
	at kafka.log.Log.renameDir(Log.scala:964)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:925)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:479)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:470)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:360)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:404)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:206)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:402)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:131)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:70)
	at java.lang.Thread.run(Thread.java:748)
	Suppressed: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-2 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-2.9f75731fb4994123999d8ae0782ca8db-delete
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-02-23 22:15:40,671] TRACE [Controller id=0 epoch=1] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=56,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=56,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=56,_tagged_fields={}}],_tagged_fields={}} for request STOP_REPLICA with correlation id 7 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:15:40,681] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-2 from ReplicaDeletionStarted to ReplicaDeletionIneligible (state.change.logger)
[2020-02-23 22:15:40,681] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-0 from ReplicaDeletionStarted to ReplicaDeletionIneligible (state.change.logger)
[2020-02-23 22:15:40,681] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-1 from ReplicaDeletionStarted to ReplicaDeletionIneligible (state.change.logger)
[2020-02-23 22:15:40,703] TRACE [Controller id=0 epoch=1] Changed state of replica 0 for partition mysecond-2 from ReplicaDeletionIneligible to OfflineReplica (state.change.logger)
[2020-02-23 22:27:21,318] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-2 from OnlineReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:27:21,319] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-1 from OnlineReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:27:21,319] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-0 from OnlineReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:27:21,320] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition myfirst-1 from OnlineReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:27:21,321] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition myfirst-2 from OnlineReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:27:21,321] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition myfirst-0 from OnlineReplica to OnlineReplica (state.change.logger)
[2020-02-23 22:27:21,328] TRACE [Controller id=0 epoch=2] Sending become-follower LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=-1, leaderEpoch=2, isr=[0], zkVersion=2, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) to broker 0 for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:21,328] TRACE [Controller id=0 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) to broker 0 for partition myfirst-2 (state.change.logger)
[2020-02-23 22:27:21,328] TRACE [Controller id=0 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) to broker 0 for partition myfirst-1 (state.change.logger)
[2020-02-23 22:27:21,328] TRACE [Controller id=0 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) to broker 0 for partition myfirst-0 (state.change.logger)
[2020-02-23 22:27:21,329] TRACE [Controller id=0 epoch=2] Sending become-follower LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=-1, leaderEpoch=2, isr=[0], zkVersion=2, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) to broker 0 for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:21,329] TRACE [Controller id=0 epoch=2] Sending become-follower LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=-1, leaderEpoch=2, isr=[0], zkVersion=2, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) to broker 0 for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:21,336] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:21,336] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition myfirst-2 (state.change.logger)
[2020-02-23 22:27:21,336] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition myfirst-1 (state.change.logger)
[2020-02-23 22:27:21,336] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition myfirst-0 (state.change.logger)
[2020-02-23 22:27:21,336] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:21,336] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:21,454] TRACE [Controller id=0 epoch=2] Changed partition mysecond-0 state from OfflinePartition to OfflinePartition (state.change.logger)
[2020-02-23 22:27:21,460] TRACE [Controller id=0 epoch=2] Changed partition mysecond-1 state from OfflinePartition to OfflinePartition (state.change.logger)
[2020-02-23 22:27:21,461] TRACE [Controller id=0 epoch=2] Changed partition mysecond-2 state from OfflinePartition to OfflinePartition (state.change.logger)
[2020-02-23 22:27:21,464] TRACE [Controller id=0 epoch=2] Changed partition mysecond-0 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-02-23 22:27:21,464] TRACE [Controller id=0 epoch=2] Changed partition mysecond-1 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-02-23 22:27:21,465] TRACE [Controller id=0 epoch=2] Changed partition mysecond-2 state from OfflinePartition to NonExistentPartition (state.change.logger)
[2020-02-23 22:27:21,467] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:21,467] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:21,467] TRACE [Controller id=0 epoch=2] Sending UpdateMetadata request UpdateMetadataPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=-2, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) to brokers HashSet(0) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:21,637] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-2 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-02-23 22:27:21,638] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-0 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-02-23 22:27:21,639] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-1 from OnlineReplica to OfflineReplica (state.change.logger)
[2020-02-23 22:27:21,645] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-0 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-02-23 22:27:21,645] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-1 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-02-23 22:27:21,645] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-2 from OfflineReplica to ReplicaDeletionStarted (state.change.logger)
[2020-02-23 22:27:21,933] TRACE [Controller id=0 epoch=2] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 0 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:27:21,960] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) correlation id 1 from controller 0 epoch 2 (state.change.logger)
[2020-02-23 22:27:21,960] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) correlation id 1 from controller 0 epoch 2 (state.change.logger)
[2020-02-23 22:27:21,960] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) correlation id 1 from controller 0 epoch 2 (state.change.logger)
[2020-02-23 22:27:21,960] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=2, controllerEpoch=1, leader=-1, leaderEpoch=2, isr=[0], zkVersion=2, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) correlation id 1 from controller 0 epoch 2 (state.change.logger)
[2020-02-23 22:27:21,960] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=0, controllerEpoch=1, leader=-1, leaderEpoch=2, isr=[0], zkVersion=2, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) correlation id 1 from controller 0 epoch 2 (state.change.logger)
[2020-02-23 22:27:21,960] TRACE [Broker id=0] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='mysecond', partitionIndex=1, controllerEpoch=1, leader=-1, leaderEpoch=2, isr=[0], zkVersion=2, replicas=[0], addingReplicas=[], removingReplicas=[], isNew=false) correlation id 1 from controller 0 epoch 2 (state.change.logger)
[2020-02-23 22:27:22,053] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-leader transition for partition myfirst-0 (state.change.logger)
[2020-02-23 22:27:22,053] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-leader transition for partition myfirst-1 (state.change.logger)
[2020-02-23 22:27:22,053] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-leader transition for partition myfirst-2 (state.change.logger)
[2020-02-23 22:27:22,101] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 2 with correlation id 1 for partition myfirst-0 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:27:22,109] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 2 with correlation id 1 for partition myfirst-1 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:27:22,118] TRACE [Broker id=0] Stopped fetchers as part of become-leader request from controller 0 epoch 2 with correlation id 1 for partition myfirst-2 (last update controller epoch 1) (state.change.logger)
[2020-02-23 22:27:22,120] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-leader transition for partition myfirst-0 (state.change.logger)
[2020-02-23 22:27:22,120] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-leader transition for partition myfirst-1 (state.change.logger)
[2020-02-23 22:27:22,120] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-leader transition for partition myfirst-2 (state.change.logger)
[2020-02-23 22:27:22,121] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-follower transition for partition mysecond-0 with leader -1 (state.change.logger)
[2020-02-23 22:27:22,122] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-follower transition for partition mysecond-2 with leader -1 (state.change.logger)
[2020-02-23 22:27:22,122] TRACE [Broker id=0] Handling LeaderAndIsr request correlationId 1 from controller 0 epoch 2 starting the become-follower transition for partition mysecond-1 with leader -1 (state.change.logger)
[2020-02-23 22:27:22,125] ERROR [Broker id=0] Received LeaderAndIsrRequest with correlation id 1 from controller 0 epoch 2 for partition mysecond-0 (last update controller epoch 1) but cannot become follower since the new leader -1 is unavailable. (state.change.logger)
[2020-02-23 22:27:22,129] ERROR [Broker id=0] Received LeaderAndIsrRequest with correlation id 1 from controller 0 epoch 2 for partition mysecond-2 (last update controller epoch 1) but cannot become follower since the new leader -1 is unavailable. (state.change.logger)
[2020-02-23 22:27:22,132] ERROR [Broker id=0] Received LeaderAndIsrRequest with correlation id 1 from controller 0 epoch 2 for partition mysecond-1 (last update controller epoch 1) but cannot become follower since the new leader -1 is unavailable. (state.change.logger)
[2020-02-23 22:27:22,149] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-follower transition for partition mysecond-0 with leader -1 (state.change.logger)
[2020-02-23 22:27:22,149] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-follower transition for partition mysecond-2 with leader -1 (state.change.logger)
[2020-02-23 22:27:22,150] TRACE [Broker id=0] Completed LeaderAndIsr request correlationId 1 from controller 0 epoch 2 for the become-follower transition for partition mysecond-1 with leader -1 (state.change.logger)
[2020-02-23 22:27:22,167] TRACE [Controller id=0 epoch=2] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=myfirst,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=myfirst,partition_index=1,error_code=0,_tagged_fields={}},{topic_name=myfirst,partition_index=0,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=0,_tagged_fields={}}],_tagged_fields={}} for request LEADER_AND_ISR with correlation id 1 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:27:22,179] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=2, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition myfirst-2 in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2020-02-23 22:27:22,179] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=1, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition myfirst-1 in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2020-02-23 22:27:22,179] TRACE [Broker id=0] Cached leader info UpdateMetadataPartitionState(topicName='myfirst', partitionIndex=0, controllerEpoch=1, leader=0, leaderEpoch=0, isr=[0], zkVersion=0, replicas=[0], offlineReplicas=[]) for partition myfirst-0 in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2020-02-23 22:27:22,181] TRACE [Broker id=0] Deleted partition mysecond-2 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2020-02-23 22:27:22,181] TRACE [Broker id=0] Deleted partition mysecond-0 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2020-02-23 22:27:22,181] TRACE [Broker id=0] Deleted partition mysecond-1 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 2 (state.change.logger)
[2020-02-23 22:27:22,185] TRACE [Controller id=0 epoch=2] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 2 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:27:22,188] TRACE [Broker id=0] Deleted partition mysecond-2 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 3 (state.change.logger)
[2020-02-23 22:27:22,188] TRACE [Broker id=0] Deleted partition mysecond-0 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 3 (state.change.logger)
[2020-02-23 22:27:22,188] TRACE [Broker id=0] Deleted partition mysecond-1 from metadata cache in response to UpdateMetadata request sent by controller 0 epoch 2 with correlation id 3 (state.change.logger)
[2020-02-23 22:27:22,189] TRACE [Controller id=0 epoch=2] Received response {error_code=0,_tagged_fields={}} for request UPDATE_METADATA with correlation id 3 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:27:22,199] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:22,202] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:22,202] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:22,202] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:22,203] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:22,203] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:22,207] TRACE [Controller id=0 epoch=2] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=0,_tagged_fields={}}],_tagged_fields={}} for request STOP_REPLICA with correlation id 4 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:27:22,210] TRACE [Broker id=0] Handling stop replica (delete=true) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:22,240] ERROR [Broker id=0] Ignoring stop replica (delete=true) for partition mysecond-0 due to storage exception (state.change.logger)
org.apache.kafka.common.errors.KafkaStorageException: Error while renaming dir for mysecond-0 in log dir C:\kafka_2.13-2.4.0\data\kafka
Caused by: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-0 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-0.73f140aab6184027baad8102544bbbc9-delete
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:966)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2316)
	at kafka.log.Log.renameDir(Log.scala:964)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:925)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:479)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:470)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:360)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:404)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:206)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:402)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:131)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:70)
	at java.lang.Thread.run(Thread.java:748)
	Suppressed: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-0 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-0.73f140aab6184027baad8102544bbbc9-delete
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-02-23 22:27:22,240] TRACE [Broker id=0] Handling stop replica (delete=true) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:22,254] ERROR [Broker id=0] Ignoring stop replica (delete=true) for partition mysecond-1 due to storage exception (state.change.logger)
org.apache.kafka.common.errors.KafkaStorageException: Error while renaming dir for mysecond-1 in log dir C:\kafka_2.13-2.4.0\data\kafka
Caused by: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-1 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-1.84fcf6d44d294deb8c017b33007f1aa5-delete
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:966)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2316)
	at kafka.log.Log.renameDir(Log.scala:964)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:925)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:479)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:470)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:360)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:404)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:206)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:402)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:131)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:70)
	at java.lang.Thread.run(Thread.java:748)
	Suppressed: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-1 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-1.84fcf6d44d294deb8c017b33007f1aa5-delete
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-02-23 22:27:22,255] TRACE [Broker id=0] Handling stop replica (delete=true) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:22,270] ERROR [Broker id=0] Ignoring stop replica (delete=true) for partition mysecond-2 due to storage exception (state.change.logger)
org.apache.kafka.common.errors.KafkaStorageException: Error while renaming dir for mysecond-2 in log dir C:\kafka_2.13-2.4.0\data\kafka
Caused by: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-2 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-2.0337df4ca82c4c5c892cd3ec7a42d8c7-delete
	at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
	at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
	at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:387)
	at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
	at java.nio.file.Files.move(Files.java:1395)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:795)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:966)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2316)
	at kafka.log.Log.renameDir(Log.scala:964)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:925)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:479)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:470)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:360)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:404)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:206)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:402)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:235)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:131)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:70)
	at java.lang.Thread.run(Thread.java:748)
	Suppressed: java.nio.file.AccessDeniedException: C:\kafka_2.13-2.4.0\data\kafka\mysecond-2 -> C:\kafka_2.13-2.4.0\data\kafka\mysecond-2.0337df4ca82c4c5c892cd3ec7a42d8c7-delete
		at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:83)
		at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:97)
		at sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:301)
		at sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:287)
		at java.nio.file.Files.move(Files.java:1395)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:792)
		... 17 more
[2020-02-23 22:27:22,273] TRACE [Controller id=0 epoch=2] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=56,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=56,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=56,_tagged_fields={}}],_tagged_fields={}} for request STOP_REPLICA with correlation id 5 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
[2020-02-23 22:27:22,280] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-2 from ReplicaDeletionStarted to ReplicaDeletionIneligible (state.change.logger)
[2020-02-23 22:27:22,280] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-0 from ReplicaDeletionStarted to ReplicaDeletionIneligible (state.change.logger)
[2020-02-23 22:27:22,280] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-1 from ReplicaDeletionStarted to ReplicaDeletionIneligible (state.change.logger)
[2020-02-23 22:27:22,297] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-2 from ReplicaDeletionIneligible to OfflineReplica (state.change.logger)
[2020-02-23 22:27:22,297] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-0 from ReplicaDeletionIneligible to OfflineReplica (state.change.logger)
[2020-02-23 22:27:22,297] TRACE [Controller id=0 epoch=2] Changed state of replica 0 for partition mysecond-1 from ReplicaDeletionIneligible to OfflineReplica (state.change.logger)
[2020-02-23 22:27:22,301] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:22,301] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-0 (state.change.logger)
[2020-02-23 22:27:22,301] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:22,301] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-1 (state.change.logger)
[2020-02-23 22:27:22,301] TRACE [Broker id=0] Handling stop replica (delete=false) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:22,301] TRACE [Broker id=0] Finished handling stop replica (delete=false) for partition mysecond-2 (state.change.logger)
[2020-02-23 22:27:22,303] TRACE [Controller id=0 epoch=2] Received response {error_code=0,partition_errors=[{topic_name=mysecond,partition_index=2,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=0,error_code=0,_tagged_fields={}},{topic_name=mysecond,partition_index=1,error_code=0,_tagged_fields={}}],_tagged_fields={}} for request STOP_REPLICA with correlation id 6 sent to broker DELL-PC:9092 (id: 0 rack: null) (state.change.logger)
